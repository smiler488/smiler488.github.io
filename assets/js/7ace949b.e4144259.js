"use strict";(self.webpackChunkliangchao_website=self.webpackChunkliangchao_website||[]).push([[7985],{10261:n=>{n.exports=JSON.parse('{"permalink":"/blog/pytorch-ml-dl-tutorial","editUrl":"https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/blog/2022-09-20-pytorch-ml-dl-tutorial.md","source":"@site/blog/2022-09-20-pytorch-ml-dl-tutorial.md","title":"PyTorch Tutorial","description":"Introduction","date":"2022-09-20T00:00:00.000Z","tags":[{"inline":false,"label":"PyTorch","permalink":"/blog/tags/pytorch","description":"PyTorch deep learning framework"},{"inline":false,"label":"Machine Learning","permalink":"/blog/tags/machine-learning","description":"Machine learning techniques and applications"},{"inline":false,"label":"Deep Learning","permalink":"/blog/tags/deep-learning","description":"Deep learning techniques and neural networks"},{"inline":false,"label":"Neural Networks","permalink":"/blog/tags/neural-networks","description":"Neural network architectures and implementations"},{"inline":false,"label":"Tutorial","permalink":"/blog/tags/tutorial","description":"Tutorial tag description"}],"readingTime":39.9,"hasTruncateMarker":true,"authors":[{"name":"Liangchao Deng","title":"Ph.D. Candidate @ SHZU @CAS-Cemps","url":"https://github.com/smiler488","page":{"permalink":"/blog/authors/liangchao"},"socials":{"x":"https://x.com/smiler488","github":"https://github.com/smiler488"},"imageURL":"/img/cv_person.png","key":"liangchao"}],"frontMatter":{"slug":"pytorch-ml-dl-tutorial","title":"PyTorch Tutorial","authors":["liangchao"],"tags":["pytorch","machine learning","deep learning","neural networks","tutorial"]},"unlisted":false,"prevItem":{"title":"Complete Workflow for DJI P4M Multispectral Image Processing with WebODM and QGIS","permalink":"/blog/dji-p4m-webodm-qgis-workflow"},"nextItem":{"title":"3D Reconstruction of Potted Cotton Plants in a Controlled-Environment Growth Chamber","permalink":"/blog/growth-chamber-cotton-3d"}}')},28453:(n,e,t)=>{t.d(e,{R:()=>o,x:()=>a});var r=t(96540);const s={},i=r.createContext(s);function o(n){const e=r.useContext(i);return r.useMemo((function(){return"function"==typeof n?n(e):{...e,...n}}),[e,n])}function a(n){let e;return e=n.disableParentContext?"function"==typeof n.components?n.components(s):n.components||s:o(n.components),r.createElement(i.Provider,{value:e},n.children)}},95379:(n,e,t)=>{t.r(e),t.d(e,{assets:()=>l,contentTitle:()=>a,default:()=>p,frontMatter:()=>o,metadata:()=>r,toc:()=>d});var r=t(10261),s=t(74848),i=t(28453);const o={slug:"pytorch-ml-dl-tutorial",title:"PyTorch Tutorial",authors:["liangchao"],tags:["pytorch","machine learning","deep learning","neural networks","tutorial"]},a="Complete PyTorch Tutorial for Machine Learning and Deep Learning",l={authorsImageUrls:[void 0]},d=[{value:"Introduction",id:"introduction",level:2},{value:"Table of Contents",id:"table-of-contents",level:2},{value:"Quick Start (15 Minutes)",id:"quick-start-15-minutes",level:2},{value:"Step 1: Install PyTorch (3 minutes)",id:"step-1-install-pytorch-3-minutes",level:3},{value:"Step 2: Verify Installation (2 minutes)",id:"step-2-verify-installation-2-minutes",level:3},{value:"Step 3: Train Your First Neural Network (10 minutes)",id:"step-3-train-your-first-neural-network-10-minutes",level:3},{value:"Hardware Requirements",id:"hardware-requirements",level:3},{value:"Next Steps",id:"next-steps",level:3},{value:"PyTorch Fundamentals",id:"pytorch-fundamentals",level:2},{value:"Installation and Setup",id:"installation-and-setup",level:3},{value:"Basic Tensor Operations",id:"basic-tensor-operations",level:3},{value:"Data Handling and Preprocessing",id:"data-handling-and-preprocessing",level:2},{value:"Dataset and DataLoader",id:"dataset-and-dataloader",level:3},{value:"Building Neural Networks",id:"building-neural-networks",level:2},{value:"Basic Neural Network Components",id:"basic-neural-network-components",level:3},{value:"Training and Optimization",id:"training-and-optimization",level:2},{value:"Training Loop Implementation",id:"training-loop-implementation",level:3},{value:"Computer Vision with PyTorch",id:"computer-vision-with-pytorch",level:2},{value:"Transfer Learning and Fine-tuning",id:"transfer-learning-and-fine-tuning",level:3},{value:"Natural Language Processing",id:"natural-language-processing",level:2},{value:"Text Processing and RNN/Transformer Models",id:"text-processing-and-rnntransformer-models",level:3},{value:"Advanced Topics",id:"advanced-topics",level:2},{value:"Custom Loss Functions and Metrics",id:"custom-loss-functions-and-metrics",level:3},{value:"Production Deployment",id:"production-deployment",level:2},{value:"Model Optimization and Deployment",id:"model-optimization-and-deployment",level:3},{value:"Troubleshooting",id:"troubleshooting",level:2},{value:"1. CUDA Out of Memory Error",id:"1-cuda-out-of-memory-error",level:3},{value:"2. PyTorch Installation Issues",id:"2-pytorch-installation-issues",level:3},{value:"3. Version Compatibility Errors",id:"3-version-compatibility-errors",level:3},{value:"4. DataLoader Worker Errors",id:"4-dataloader-worker-errors",level:3},{value:"5. Model Device Mismatch",id:"5-model-device-mismatch",level:3},{value:"6. Gradient Computation Errors",id:"6-gradient-computation-errors",level:3},{value:"7. Import and Module Errors",id:"7-import-and-module-errors",level:3},{value:"8. Training Performance Issues",id:"8-training-performance-issues",level:3},{value:"9. Model Saving and Loading Issues",id:"9-model-saving-and-loading-issues",level:3},{value:"10. Distributed Training Errors",id:"10-distributed-training-errors",level:3},{value:"Additional Troubleshooting Resources",id:"additional-troubleshooting-resources",level:3},{value:"Environment Validation Script",id:"environment-validation-script",level:3},{value:"Conclusion",id:"conclusion",level:2},{value:"Core Concepts Covered",id:"core-concepts-covered",level:3},{value:"Best Practices",id:"best-practices",level:3},{value:"Next Steps",id:"next-steps-1",level:3}];function c(n){const e={a:"a",code:"code",em:"em",h2:"h2",h3:"h3",hr:"hr",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,i.R)(),...n.components};return(0,s.jsxs)(s.Fragment,{children:[(0,s.jsx)(e.h2,{id:"introduction",children:"Introduction"}),"\n",(0,s.jsx)(e.p,{children:"PyTorch is one of the most popular deep learning frameworks, known for its dynamic computation graphs, intuitive API, and strong community support. This comprehensive tutorial covers everything from basic tensor operations to advanced deep learning architectures, providing practical examples and best practices for both machine learning and deep learning applications."}),"\n",(0,s.jsx)(e.h2,{id:"table-of-contents",children:"Table of Contents"}),"\n",(0,s.jsxs)(e.ol,{children:["\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.a,{href:"#quick-start-15-minutes",children:"Quick Start (15 Minutes)"})," \u26a1"]}),"\n",(0,s.jsx)(e.li,{children:(0,s.jsx)(e.a,{href:"#pytorch-fundamentals",children:"PyTorch Fundamentals"})}),"\n",(0,s.jsx)(e.li,{children:(0,s.jsx)(e.a,{href:"#data-handling-and-preprocessing",children:"Data Handling and Preprocessing"})}),"\n",(0,s.jsx)(e.li,{children:(0,s.jsx)(e.a,{href:"#building-neural-networks",children:"Building Neural Networks"})}),"\n",(0,s.jsx)(e.li,{children:(0,s.jsx)(e.a,{href:"#training-and-optimization",children:"Training and Optimization"})}),"\n",(0,s.jsx)(e.li,{children:(0,s.jsx)(e.a,{href:"#computer-vision-with-pytorch",children:"Computer Vision with PyTorch"})}),"\n",(0,s.jsx)(e.li,{children:(0,s.jsx)(e.a,{href:"#natural-language-processing",children:"Natural Language Processing"})}),"\n",(0,s.jsx)(e.li,{children:(0,s.jsx)(e.a,{href:"#advanced-topics",children:"Advanced Topics"})}),"\n",(0,s.jsx)(e.li,{children:(0,s.jsx)(e.a,{href:"#production-deployment",children:"Production Deployment"})}),"\n",(0,s.jsx)(e.li,{children:(0,s.jsx)(e.a,{href:"#troubleshooting",children:"Troubleshooting"})}),"\n"]}),"\n",(0,s.jsx)(e.h2,{id:"quick-start-15-minutes",children:"Quick Start (15 Minutes)"}),"\n",(0,s.jsxs)(e.p,{children:[(0,s.jsx)(e.strong,{children:"Goal:"})," Get PyTorch running and train your first neural network in 15 minutes."]}),"\n",(0,s.jsx)(e.h3,{id:"step-1-install-pytorch-3-minutes",children:"Step 1: Install PyTorch (3 minutes)"}),"\n",(0,s.jsx)(e.p,{children:"Choose the installation method based on your hardware:"}),"\n",(0,s.jsx)(e.pre,{children:(0,s.jsx)(e.code,{className:"language-bash",children:"# Option 1: GPU with CUDA (Recommended for deep learning)\npip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\n\n# Option 2: CPU only (Good for learning basics)\npip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cpu\n\n# Option 3: Mac with Apple Silicon (M1/M2/M3)\npip install torch torchvision torchaudio\n"})}),"\n",(0,s.jsx)(e.h3,{id:"step-2-verify-installation-2-minutes",children:"Step 2: Verify Installation (2 minutes)"}),"\n",(0,s.jsxs)(e.p,{children:["Create a file ",(0,s.jsx)(e.code,{children:"check_pytorch_env.py"}),":"]}),"\n",(0,s.jsx)(e.pre,{children:(0,s.jsx)(e.code,{className:"language-python",children:'#!/usr/bin/env python3\n"""\nPyTorch Environment Check Script\nVerifies PyTorch installation and hardware capabilities\n"""\nimport sys\n\ndef check_pytorch_installation():\n    """Check if PyTorch is installed and working"""\n    print("=" * 60)\n    print("PyTorch Environment Check")\n    print("=" * 60)\n\n    # Check PyTorch installation\n    try:\n        import torch\n        print(f"\u2713 PyTorch installed: version {torch.__version__}")\n    except ImportError:\n        print("\u2717 PyTorch not installed")\n        print("  Install with: pip install torch torchvision torchaudio")\n        return False\n\n    # Check CUDA availability\n    print(f"\\n{\'CUDA Support\':.<40} ", end="")\n    if torch.cuda.is_available():\n        print(f"\u2713 Available")\n        print(f"{\'  CUDA Version\':.<40} {torch.version.cuda}")\n        print(f"{\'  Device Count\':.<40} {torch.cuda.device_count()}")\n        for i in range(torch.cuda.device_count()):\n            props = torch.cuda.get_device_properties(i)\n            print(f"{\'  GPU \' + str(i):.<40} {props.name}")\n            print(f"{\'    Memory\':.<40} {props.total_memory / 1024**3:.1f} GB")\n            print(f"{\'    Compute Capability\':.<40} {props.major}.{props.minor}")\n    else:\n        print("\u2717 Not available (CPU only)")\n        print("  For GPU support, install CUDA-enabled PyTorch")\n\n    # Check MPS (Apple Silicon) availability\n    if hasattr(torch.backends, \'mps\'):\n        print(f"\\n{\'Apple MPS Support\':.<40} ", end="")\n        if torch.backends.mps.is_available():\n            print("\u2713 Available")\n        else:\n            print("\u2717 Not available")\n\n    # Test basic tensor operations\n    print(f"\\n{\'Testing Basic Operations\':.<40} ", end="")\n    try:\n        x = torch.randn(3, 3)\n        y = torch.randn(3, 3)\n        z = x @ y  # Matrix multiplication\n        print("\u2713 Success")\n    except Exception as e:\n        print(f"\u2717 Failed: {e}")\n        return False\n\n    # Test device transfer\n    if torch.cuda.is_available():\n        print(f"{\'Testing GPU Transfer\':.<40} ", end="")\n        try:\n            x_gpu = x.cuda()\n            y_gpu = y.cuda()\n            z_gpu = x_gpu @ y_gpu\n            print("\u2713 Success")\n        except Exception as e:\n            print(f"\u2717 Failed: {e}")\n\n    # Check additional packages\n    print(f"\\n{\'Additional Packages\':-^60}")\n    packages = {\n        \'torchvision\': \'Image processing\',\n        \'numpy\': \'Numerical computing\',\n        \'matplotlib\': \'Plotting\',\n        \'scikit-learn\': \'ML utilities\',\n    }\n\n    for package, description in packages.items():\n        try:\n            __import__(package)\n            print(f"  \u2713 {package:.<30} {description}")\n        except ImportError:\n            print(f"  \u2717 {package:.<30} Not installed")\n\n    print("\\n" + "=" * 60)\n    print("Environment check complete!")\n    print("=" * 60)\n    return True\n\nif __name__ == "__main__":\n    success = check_pytorch_installation()\n    sys.exit(0 if success else 1)\n'})}),"\n",(0,s.jsx)(e.p,{children:"Run the script:"}),"\n",(0,s.jsx)(e.pre,{children:(0,s.jsx)(e.code,{className:"language-bash",children:"python check_pytorch_env.py\n"})}),"\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"Expected output:"})}),"\n",(0,s.jsx)(e.pre,{children:(0,s.jsx)(e.code,{children:"============================================================\nPyTorch Environment Check\n============================================================\n\u2713 PyTorch installed: version 2.1.0\n\nCUDA Support................................ \u2713 Available\n  CUDA Version.............................. 11.8\n  Device Count.............................. 1\n  GPU 0..................................... NVIDIA GeForce RTX 3090\n    Memory.................................. 24.0 GB\n    Compute Capability...................... 8.6\n\nTesting Basic Operations.................... \u2713 Success\nTesting GPU Transfer........................ \u2713 Success\n\n-------------------Additional Packages--------------------\n  \u2713 torchvision..................... Image processing\n  \u2713 numpy........................... Numerical computing\n  \u2713 matplotlib...................... Plotting\n  \u2713 scikit-learn.................... ML utilities\n"})}),"\n",(0,s.jsx)(e.h3,{id:"step-3-train-your-first-neural-network-10-minutes",children:"Step 3: Train Your First Neural Network (10 minutes)"}),"\n",(0,s.jsx)(e.p,{children:"Create a simple neural network that learns XOR operation:"}),"\n",(0,s.jsx)(e.pre,{children:(0,s.jsx)(e.code,{className:"language-python",children:'import torch\nimport torch.nn as nn\nimport torch.optim as optim\n\n# Step 1: Define the network\nclass SimpleNN(nn.Module):\n    def __init__(self):\n        super(SimpleNN, self).__init__()\n        self.layer1 = nn.Linear(2, 4)  # Input: 2 features, Hidden: 4 neurons\n        self.layer2 = nn.Linear(4, 1)  # Hidden: 4 neurons, Output: 1\n\n    def forward(self, x):\n        x = torch.relu(self.layer1(x))\n        x = torch.sigmoid(self.layer2(x))\n        return x\n\n# Step 2: Prepare data (XOR problem)\nX = torch.tensor([[0, 0], [0, 1], [1, 0], [1, 1]], dtype=torch.float32)\ny = torch.tensor([[0], [1], [1], [0]], dtype=torch.float32)\n\n# Step 3: Create model, loss function, and optimizer\nmodel = SimpleNN()\ncriterion = nn.BCELoss()  # Binary Cross Entropy Loss\noptimizer = optim.Adam(model.parameters(), lr=0.1)\n# Set random seed for reproducibility\ntorch.manual_seed(42)\n\n# Step 4: Train the model\nprint("Training XOR Neural Network...")\nfor epoch in range(1000):\n    # Forward pass\n    outputs = model(X)\n    loss = criterion(outputs, y)\n\n    # Backward pass and optimization\n    optimizer.zero_grad()\n    loss.backward()\n    optimizer.step()\n\n    # Print progress every 200 epochs\n    if (epoch + 1) % 200 == 0:\n        print(f\'Epoch [{epoch+1}/1000], Loss: {loss.item():.4f}\')\n\n# Step 5: Test the model\nprint("\\nTesting the trained model:")\nwith torch.no_grad():\n    predictions = model(X)\n    for i, (input_val, pred, target) in enumerate(zip(X, predictions, y)):\n        print(f"Input: {input_val.numpy()}, Predicted: {pred.item():.4f}, Target: {target.item():.0f}")\n'})}),"\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"Expected output:"})}),"\n",(0,s.jsx)(e.pre,{children:(0,s.jsx)(e.code,{children:"Training XOR Neural Network...\nEpoch [200/1000], Loss: 0.3847\nEpoch [400/1000], Loss: 0.0823\nEpoch [600/1000], Loss: 0.0234\nEpoch [800/1000], Loss: 0.0103\nEpoch [1000/1000], Loss: 0.0059\n\nTesting the trained model:\nInput: [0. 0.], Predicted: 0.0156, Target: 0\nInput: [0. 1.], Predicted: 0.9821, Target: 1\nInput: [1. 0.], Predicted: 0.9834, Target: 1\nInput: [1. 1.], Predicted: 0.0198, Target: 0\n"})}),"\n",(0,s.jsxs)(e.p,{children:[(0,s.jsx)(e.strong,{children:"Congratulations!"})," You've successfully:"]}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsx)(e.li,{children:"Installed PyTorch"}),"\n",(0,s.jsx)(e.li,{children:"Verified your environment"}),"\n",(0,s.jsx)(e.li,{children:"Trained your first neural network"}),"\n",(0,s.jsx)(e.li,{children:"Made predictions"}),"\n"]}),"\n",(0,s.jsx)(e.h3,{id:"hardware-requirements",children:"Hardware Requirements"}),"\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"For Learning (Chapters 1-4):"})}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsx)(e.li,{children:"CPU: Any modern processor"}),"\n",(0,s.jsx)(e.li,{children:"RAM: 8 GB minimum"}),"\n",(0,s.jsx)(e.li,{children:"GPU: Optional"}),"\n"]}),"\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"For Deep Learning (Chapters 5-8):"})}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsx)(e.li,{children:"CPU: Multi-core processor (8+ cores recommended)"}),"\n",(0,s.jsx)(e.li,{children:"RAM: 16 GB minimum, 32 GB recommended"}),"\n",(0,s.jsx)(e.li,{children:"GPU: NVIDIA GPU with 8 GB+ VRAM (RTX 3060, RTX 4060 Ti, or better)"}),"\n",(0,s.jsx)(e.li,{children:"Storage: 50 GB free space for datasets and models"}),"\n"]}),"\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"Cloud Alternatives (if local hardware insufficient):"})}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Google Colab"})," (Free): Free T4 GPU, good for learning"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Kaggle Notebooks"})," (Free): Free P100 GPU, 30 hours/week"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Paperspace Gradient"})," (Paid): Starting at $0.45/hour for RTX 4000"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"AWS SageMaker"})," (Paid): Various GPU instances available"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Lambda Labs"})," (Paid): Cost-effective GPU cloud starting at $0.50/hour"]}),"\n"]}),"\n",(0,s.jsx)(e.h3,{id:"next-steps",children:"Next Steps"}),"\n",(0,s.jsx)(e.p,{children:"Now you're ready to dive deeper:"}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Beginners:"})," Continue with ",(0,s.jsx)(e.a,{href:"#pytorch-fundamentals",children:"PyTorch Fundamentals"})," to understand tensors, autograd, and basic operations"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Intermediate:"})," Jump to ",(0,s.jsx)(e.a,{href:"#building-neural-networks",children:"Building Neural Networks"})," to learn CNN, RNN architectures"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Advanced:"})," Explore ",(0,s.jsx)(e.a,{href:"#advanced-topics",children:"Advanced Topics"})," for custom losses, GradCAM, and knowledge distillation"]}),"\n"]}),"\n",(0,s.jsx)(e.h2,{id:"pytorch-fundamentals",children:"PyTorch Fundamentals"}),"\n",(0,s.jsx)(e.h3,{id:"installation-and-setup",children:"Installation and Setup"}),"\n",(0,s.jsx)(e.pre,{children:(0,s.jsx)(e.code,{className:"language-bash",children:"# Install PyTorch with CUDA support\npip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\n\n# For CPU-only installation\npip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cpu\n\n# Additional packages\npip install numpy matplotlib scikit-learn pandas seaborn jupyter\n"})}),"\n",(0,s.jsx)(e.h3,{id:"basic-tensor-operations",children:"Basic Tensor Operations"}),"\n",(0,s.jsx)(e.pre,{children:(0,s.jsx)(e.code,{className:"language-python",children:'import torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport torch.nn.functional as F\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# Check PyTorch version and CUDA availability\nprint(f"PyTorch version: {torch.__version__}")\nprint(f"CUDA available: {torch.cuda.is_available()}")\nprint(f"CUDA version: {torch.version.cuda}")\n\n# Creating tensors\ndef tensor_basics():\n    # Different ways to create tensors\n    x1 = torch.tensor([1, 2, 3, 4, 5])\n    x2 = torch.zeros(3, 4)\n    x3 = torch.ones(2, 3)\n    x4 = torch.randn(2, 3)  # Random normal distribution\n    x5 = torch.arange(0, 10, 2)  # Range tensor\n    \n    print("Basic tensor creation:")\n    print(f"x1: {x1}")\n    print(f"x2 shape: {x2.shape}")\n    print(f"x4: {x4}")\n    \n    # Tensor properties\n    print(f"\\nTensor properties:")\n    print(f"Data type: {x4.dtype}")\n    print(f"Device: {x4.device}")\n    print(f"Shape: {x4.shape}")\n    print(f"Number of dimensions: {x4.ndim}")\n    \n    # Moving tensors to GPU\n    if torch.cuda.is_available():\n        x4_gpu = x4.cuda()\n        print(f"GPU tensor device: {x4_gpu.device}")\n    \n    return x1, x2, x3, x4, x5\n\n# Tensor operations\ndef tensor_operations():\n    # Basic arithmetic operations\n    a = torch.tensor([[1, 2], [3, 4]], dtype=torch.float32)\n    b = torch.tensor([[5, 6], [7, 8]], dtype=torch.float32)\n    \n    # Element-wise operations\n    add_result = a + b\n    mul_result = a * b\n    div_result = a / b\n    \n    # Matrix operations\n    matmul_result = torch.matmul(a, b)\n    transpose_result = a.t()\n    \n    print("Tensor operations:")\n    print(f"Addition: \\n{add_result}")\n    print(f"Matrix multiplication: \\n{matmul_result}")\n    print(f"Transpose: \\n{transpose_result}")\n    \n    # Reshaping and indexing\n    x = torch.randn(4, 6)\n    x_reshaped = x.view(2, 12)  # Reshape\n    x_slice = x[:2, :3]  # Slicing\n    \n    print(f"\\nOriginal shape: {x.shape}")\n    print(f"Reshaped: {x_reshaped.shape}")\n    print(f"Sliced: {x_slice.shape}")\n    \n    return a, b, add_result, matmul_result\n\n# Automatic differentiation\ndef autograd_example():\n    # Enable gradient computation\n    x = torch.tensor(2.0, requires_grad=True)\n    y = torch.tensor(3.0, requires_grad=True)\n    \n    # Forward pass\n    z = x**2 + y**3\n    \n    # Backward pass\n    z.backward()\n    \n    print("Automatic differentiation:")\n    print(f"x.grad: {x.grad}")  # dz/dx = 2x = 4\n    print(f"y.grad: {y.grad}")  # dz/dy = 3y^2 = 27\n    \n    # More complex example\n    x = torch.randn(3, requires_grad=True)\n    y = x * 2\n    while y.data.norm() < 1000:\n        y = y * 2\n    \n    print(f"\\nFinal y: {y}")\n    \n    # Compute gradients\n    v = torch.tensor([0.1, 1.0, 0.0001], dtype=torch.float)\n    y.backward(v)\n    print(f"x.grad: {x.grad}")\n\n# Run basic examples\ntensor_basics()\ntensor_operations()\nautograd_example()\n'})}),"\n",(0,s.jsx)(e.h2,{id:"data-handling-and-preprocessing",children:"Data Handling and Preprocessing"}),"\n",(0,s.jsx)(e.h3,{id:"dataset-and-dataloader",children:"Dataset and DataLoader"}),"\n",(0,s.jsx)(e.pre,{children:(0,s.jsx)(e.code,{className:"language-python",children:"from torch.utils.data import Dataset, DataLoader\nfrom torchvision import transforms, datasets\nimport os\nfrom PIL import Image\n\n# Custom Dataset class\nclass CustomDataset(Dataset):\n    def __init__(self, data, targets, transform=None):\n        self.data = data\n        self.targets = targets\n        self.transform = transform\n    \n    def __len__(self):\n        return len(self.data)\n    \n    def __getitem__(self, idx):\n        sample = self.data[idx]\n        target = self.targets[idx]\n        \n        if self.transform:\n            sample = self.transform(sample)\n        \n        return sample, target\n\n# Image dataset example\nclass ImageDataset(Dataset):\n    def __init__(self, root_dir, transform=None):\n        self.root_dir = root_dir\n        self.transform = transform\n        self.images = []\n        self.labels = []\n        \n        # Assuming directory structure: root_dir/class_name/image.jpg\n        for class_idx, class_name in enumerate(os.listdir(root_dir)):\n            class_path = os.path.join(root_dir, class_name)\n            if os.path.isdir(class_path):\n                for img_name in os.listdir(class_path):\n                    if img_name.endswith(('.png', '.jpg', '.jpeg')):\n                        self.images.append(os.path.join(class_path, img_name))\n                        self.labels.append(class_idx)\n    \n    def __len__(self):\n        return len(self.images)\n    \n    def __getitem__(self, idx):\n        img_path = self.images[idx]\n        image = Image.open(img_path).convert('RGB')\n        label = self.labels[idx]\n        \n        if self.transform:\n            image = self.transform(image)\n        \n        return image, label\n\n# Data preprocessing and augmentation\ndef create_data_loaders():\n    # Define transforms\n    train_transform = transforms.Compose([\n        transforms.RandomResizedCrop(224),\n        transforms.RandomHorizontalFlip(p=0.5),\n        transforms.RandomRotation(degrees=15),\n        transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n        transforms.ToTensor(),\n        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n    ])\n    \n    val_transform = transforms.Compose([\n        transforms.Resize(256),\n        transforms.CenterCrop(224),\n        transforms.ToTensor(),\n        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n    ])\n    \n    # Create datasets\n    # For demonstration, using CIFAR-10\n    train_dataset = datasets.CIFAR10(\n        root='./data', \n        train=True, \n        download=True, \n        transform=train_transform\n    )\n    \n    val_dataset = datasets.CIFAR10(\n        root='./data', \n        train=False, \n        download=True, \n        transform=val_transform\n    )\n    \n    # Create data loaders\n    train_loader = DataLoader(\n        train_dataset, \n        batch_size=32, \n        shuffle=True, \n        num_workers=4,\n        pin_memory=True\n    )\n    \n    val_loader = DataLoader(\n        val_dataset, \n        batch_size=32, \n        shuffle=False, \n        num_workers=4,\n        pin_memory=True\n    )\n    \n    return train_loader, val_loader\n\n# Data exploration\ndef explore_data(data_loader):\n    # Get a batch of data\n    data_iter = iter(data_loader)\n    images, labels = next(data_iter)\n    \n    print(f\"Batch shape: {images.shape}\")\n    print(f\"Labels shape: {labels.shape}\")\n    print(f\"Data type: {images.dtype}\")\n    print(f\"Label range: {labels.min()} to {labels.max()}\")\n    \n    # Visualize some samples\n    fig, axes = plt.subplots(2, 4, figsize=(12, 6))\n    for i in range(8):\n        row, col = i // 4, i % 4\n        img = images[i].permute(1, 2, 0)  # Change from CHW to HWC\n        # Denormalize for visualization\n        img = img * torch.tensor([0.229, 0.224, 0.225]) + torch.tensor([0.485, 0.456, 0.406])\n        img = torch.clamp(img, 0, 1)\n        \n        axes[row, col].imshow(img)\n        axes[row, col].set_title(f'Label: {labels[i].item()}')\n        axes[row, col].axis('off')\n    \n    plt.tight_layout()\n    plt.show()\n\n# Create and explore data\ntrain_loader, val_loader = create_data_loaders()\nexplore_data(train_loader)\n"})}),"\n",(0,s.jsx)(e.h2,{id:"building-neural-networks",children:"Building Neural Networks"}),"\n",(0,s.jsx)(e.h3,{id:"basic-neural-network-components",children:"Basic Neural Network Components"}),"\n",(0,s.jsx)(e.pre,{children:(0,s.jsx)(e.code,{className:"language-python",children:"# Simple feedforward neural network\nclass SimpleNN(nn.Module):\n    def __init__(self, input_size, hidden_size, num_classes):\n        super(SimpleNN, self).__init__()\n        self.fc1 = nn.Linear(input_size, hidden_size)\n        self.relu = nn.ReLU()\n        self.fc2 = nn.Linear(hidden_size, hidden_size)\n        self.fc3 = nn.Linear(hidden_size, num_classes)\n        self.dropout = nn.Dropout(0.2)\n    \n    def forward(self, x):\n        x = x.view(x.size(0), -1)  # Flatten\n        x = self.fc1(x)\n        x = self.relu(x)\n        x = self.dropout(x)\n        x = self.fc2(x)\n        x = self.relu(x)\n        x = self.dropout(x)\n        x = self.fc3(x)\n        return x\n\n# Convolutional Neural Network\nclass CNN(nn.Module):\n    def __init__(self, num_classes=10):\n        super(CNN, self).__init__()\n        \n        # Convolutional layers\n        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, padding=1)\n        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n        \n        # Pooling layer\n        self.pool = nn.MaxPool2d(2, 2)\n        \n        # Batch normalization\n        self.bn1 = nn.BatchNorm2d(32)\n        self.bn2 = nn.BatchNorm2d(64)\n        self.bn3 = nn.BatchNorm2d(128)\n        \n        # Fully connected layers\n        self.fc1 = nn.Linear(128 * 4 * 4, 512)\n        self.fc2 = nn.Linear(512, num_classes)\n        \n        # Dropout\n        self.dropout = nn.Dropout(0.5)\n        \n    def forward(self, x):\n        # First conv block\n        x = self.pool(F.relu(self.bn1(self.conv1(x))))\n        \n        # Second conv block\n        x = self.pool(F.relu(self.bn2(self.conv2(x))))\n        \n        # Third conv block\n        x = self.pool(F.relu(self.bn3(self.conv3(x))))\n        \n        # Flatten\n        x = x.view(-1, 128 * 4 * 4)\n        \n        # Fully connected layers\n        x = F.relu(self.fc1(x))\n        x = self.dropout(x)\n        x = self.fc2(x)\n        \n        return x\n\n# ResNet-like block\nclass ResidualBlock(nn.Module):\n    def __init__(self, in_channels, out_channels, stride=1):\n        super(ResidualBlock, self).__init__()\n        \n        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, \n                              stride=stride, padding=1, bias=False)\n        self.bn1 = nn.BatchNorm2d(out_channels)\n        \n        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3,\n                              stride=1, padding=1, bias=False)\n        self.bn2 = nn.BatchNorm2d(out_channels)\n        \n        # Shortcut connection\n        self.shortcut = nn.Sequential()\n        if stride != 1 or in_channels != out_channels:\n            self.shortcut = nn.Sequential(\n                nn.Conv2d(in_channels, out_channels, kernel_size=1, \n                         stride=stride, bias=False),\n                nn.BatchNorm2d(out_channels)\n            )\n    \n    def forward(self, x):\n        residual = x\n        \n        out = F.relu(self.bn1(self.conv1(x)))\n        out = self.bn2(self.conv2(out))\n        \n        out += self.shortcut(residual)\n        out = F.relu(out)\n        \n        return out\n\n# Custom ResNet\nclass CustomResNet(nn.Module):\n    def __init__(self, num_classes=10):\n        super(CustomResNet, self).__init__()\n        \n        self.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)\n        self.bn1 = nn.BatchNorm2d(64)\n        \n        # Residual layers\n        self.layer1 = self._make_layer(64, 64, 2, stride=1)\n        self.layer2 = self._make_layer(64, 128, 2, stride=2)\n        self.layer3 = self._make_layer(128, 256, 2, stride=2)\n        \n        self.avg_pool = nn.AdaptiveAvgPool2d((1, 1))\n        self.fc = nn.Linear(256, num_classes)\n    \n    def _make_layer(self, in_channels, out_channels, num_blocks, stride):\n        layers = []\n        layers.append(ResidualBlock(in_channels, out_channels, stride))\n        \n        for _ in range(1, num_blocks):\n            layers.append(ResidualBlock(out_channels, out_channels))\n        \n        return nn.Sequential(*layers)\n    \n    def forward(self, x):\n        x = F.relu(self.bn1(self.conv1(x)))\n        \n        x = self.layer1(x)\n        x = self.layer2(x)\n        x = self.layer3(x)\n        \n        x = self.avg_pool(x)\n        x = x.view(x.size(0), -1)\n        x = self.fc(x)\n        \n        return x\n\n# Model initialization and summary\ndef initialize_model(model_type='cnn', num_classes=10):\n    if model_type == 'simple':\n        model = SimpleNN(input_size=32*32*3, hidden_size=512, num_classes=num_classes)\n    elif model_type == 'cnn':\n        model = CNN(num_classes=num_classes)\n    elif model_type == 'resnet':\n        model = CustomResNet(num_classes=num_classes)\n    else:\n        raise ValueError(\"Unknown model type\")\n    \n    # Initialize weights\n    def init_weights(m):\n        if isinstance(m, nn.Linear):\n            torch.nn.init.xavier_uniform_(m.weight)\n            m.bias.data.fill_(0.01)\n        elif isinstance(m, nn.Conv2d):\n            torch.nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n    \n    model.apply(init_weights)\n    \n    # Model summary\n    total_params = sum(p.numel() for p in model.parameters())\n    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n    \n    print(f\"Model: {model_type}\")\n    print(f\"Total parameters: {total_params:,}\")\n    print(f\"Trainable parameters: {trainable_params:,}\")\n    \n    return model\n\n# Test model creation\nmodel = initialize_model('resnet')\nprint(model)\n"})}),"\n",(0,s.jsx)(e.h2,{id:"training-and-optimization",children:"Training and Optimization"}),"\n",(0,s.jsx)(e.h3,{id:"training-loop-implementation",children:"Training Loop Implementation"}),"\n",(0,s.jsx)(e.pre,{children:(0,s.jsx)(e.code,{className:"language-python",children:"import time\nfrom tqdm import tqdm\nimport torch.nn.functional as F\n\nclass Trainer:\n    def __init__(self, model, train_loader, val_loader, criterion, optimizer, device):\n        self.model = model\n        self.train_loader = train_loader\n        self.val_loader = val_loader\n        self.criterion = criterion\n        self.optimizer = optimizer\n        self.device = device\n        \n        # Move model to device\n        self.model.to(device)\n        \n        # Training history\n        self.train_losses = []\n        self.train_accuracies = []\n        self.val_losses = []\n        self.val_accuracies = []\n    \n    def train_epoch(self):\n        self.model.train()\n        running_loss = 0.0\n        correct = 0\n        total = 0\n        \n        pbar = tqdm(self.train_loader, desc='Training')\n        for batch_idx, (data, target) in enumerate(pbar):\n            data, target = data.to(self.device), target.to(self.device)\n            \n            # Zero gradients\n            self.optimizer.zero_grad()\n            \n            # Forward pass\n            output = self.model(data)\n            loss = self.criterion(output, target)\n            \n            # Backward pass\n            loss.backward()\n            self.optimizer.step()\n            \n            # Statistics\n            running_loss += loss.item()\n            _, predicted = output.max(1)\n            total += target.size(0)\n            correct += predicted.eq(target).sum().item()\n            \n            # Update progress bar\n            pbar.set_postfix({\n                'Loss': f'{running_loss/(batch_idx+1):.4f}',\n                'Acc': f'{100.*correct/total:.2f}%'\n            })\n        \n        epoch_loss = running_loss / len(self.train_loader)\n        epoch_acc = 100. * correct / total\n        \n        return epoch_loss, epoch_acc\n    \n    def validate_epoch(self):\n        self.model.eval()\n        running_loss = 0.0\n        correct = 0\n        total = 0\n        \n        with torch.no_grad():\n            pbar = tqdm(self.val_loader, desc='Validation')\n            for data, target in pbar:\n                data, target = data.to(self.device), target.to(self.device)\n                \n                output = self.model(data)\n                loss = self.criterion(output, target)\n                \n                running_loss += loss.item()\n                _, predicted = output.max(1)\n                total += target.size(0)\n                correct += predicted.eq(target).sum().item()\n                \n                pbar.set_postfix({\n                    'Loss': f'{running_loss/(len(pbar.iterable)):.4f}',\n                    'Acc': f'{100.*correct/total:.2f}%'\n                })\n        \n        epoch_loss = running_loss / len(self.val_loader)\n        epoch_acc = 100. * correct / total\n        \n        return epoch_loss, epoch_acc\n    \n    def train(self, num_epochs, scheduler=None, early_stopping_patience=None):\n        best_val_acc = 0.0\n        patience_counter = 0\n        \n        for epoch in range(num_epochs):\n            print(f'\\nEpoch {epoch+1}/{num_epochs}')\n            print('-' * 50)\n            \n            # Training phase\n            train_loss, train_acc = self.train_epoch()\n            \n            # Validation phase\n            val_loss, val_acc = self.validate_epoch()\n            \n            # Update learning rate\n            if scheduler:\n                scheduler.step(val_loss)\n            \n            # Save metrics\n            self.train_losses.append(train_loss)\n            self.train_accuracies.append(train_acc)\n            self.val_losses.append(val_loss)\n            self.val_accuracies.append(val_acc)\n            \n            # Print epoch results\n            print(f'Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.2f}%')\n            print(f'Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.2f}%')\n            \n            # Early stopping\n            if early_stopping_patience:\n                if val_acc > best_val_acc:\n                    best_val_acc = val_acc\n                    patience_counter = 0\n                    # Save best model\n                    torch.save(self.model.state_dict(), 'best_model.pth')\n                else:\n                    patience_counter += 1\n                    if patience_counter >= early_stopping_patience:\n                        print(f'Early stopping triggered after {epoch+1} epochs')\n                        break\n        \n        print(f'\\nTraining completed. Best validation accuracy: {best_val_acc:.2f}%')\n    \n    def plot_training_history(self):\n        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))\n        \n        # Plot losses\n        ax1.plot(self.train_losses, label='Train Loss')\n        ax1.plot(self.val_losses, label='Validation Loss')\n        ax1.set_title('Training and Validation Loss')\n        ax1.set_xlabel('Epoch')\n        ax1.set_ylabel('Loss')\n        ax1.legend()\n        ax1.grid(True)\n        \n        # Plot accuracies\n        ax2.plot(self.train_accuracies, label='Train Accuracy')\n        ax2.plot(self.val_accuracies, label='Validation Accuracy')\n        ax2.set_title('Training and Validation Accuracy')\n        ax2.set_xlabel('Epoch')\n        ax2.set_ylabel('Accuracy (%)')\n        ax2.legend()\n        ax2.grid(True)\n        \n        plt.tight_layout()\n        plt.show()\n\n# Advanced optimization techniques\ndef setup_training(model, train_loader, val_loader):\n    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n    \n    # Loss function\n    criterion = nn.CrossEntropyLoss()\n    \n    # Optimizer with different options\n    optimizer = optim.AdamW(\n        model.parameters(), \n        lr=0.001, \n        weight_decay=0.01,\n        betas=(0.9, 0.999)\n    )\n    \n    # Learning rate scheduler\n    scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n        optimizer, \n        mode='min', \n        factor=0.5, \n        patience=5, \n        verbose=True\n    )\n    \n    # Alternative schedulers\n    # scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=50)\n    # scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=20, gamma=0.1)\n    \n    # Create trainer\n    trainer = Trainer(model, train_loader, val_loader, criterion, optimizer, device)\n    \n    return trainer, scheduler\n\n# Mixed precision training\nclass MixedPrecisionTrainer(Trainer):\n    def __init__(self, model, train_loader, val_loader, criterion, optimizer, device):\n        super().__init__(model, train_loader, val_loader, criterion, optimizer, device)\n        self.scaler = torch.cuda.amp.GradScaler()\n    \n    def train_epoch(self):\n        self.model.train()\n        running_loss = 0.0\n        correct = 0\n        total = 0\n        \n        pbar = tqdm(self.train_loader, desc='Training (Mixed Precision)')\n        for batch_idx, (data, target) in enumerate(pbar):\n            data, target = data.to(self.device), target.to(self.device)\n            \n            self.optimizer.zero_grad()\n            \n            # Mixed precision forward pass\n            with torch.cuda.amp.autocast():\n                output = self.model(data)\n                loss = self.criterion(output, target)\n            \n            # Mixed precision backward pass\n            self.scaler.scale(loss).backward()\n            self.scaler.step(self.optimizer)\n            self.scaler.update()\n            \n            # Statistics\n            running_loss += loss.item()\n            _, predicted = output.max(1)\n            total += target.size(0)\n            correct += predicted.eq(target).sum().item()\n            \n            pbar.set_postfix({\n                'Loss': f'{running_loss/(batch_idx+1):.4f}',\n                'Acc': f'{100.*correct/total:.2f}%'\n            })\n        \n        epoch_loss = running_loss / len(self.train_loader)\n        epoch_acc = 100. * correct / total\n        \n        return epoch_loss, epoch_acc\n\n# Example training setup and execution\nmodel = initialize_model('resnet', num_classes=10)\ntrainer, scheduler = setup_training(model, train_loader, val_loader)\n\n# Train the model\ntrainer.train(num_epochs=50, scheduler=scheduler, early_stopping_patience=10)\n\n# Plot training history\ntrainer.plot_training_history()\n"})}),"\n",(0,s.jsx)(e.h2,{id:"computer-vision-with-pytorch",children:"Computer Vision with PyTorch"}),"\n",(0,s.jsx)(e.h3,{id:"transfer-learning-and-fine-tuning",children:"Transfer Learning and Fine-tuning"}),"\n",(0,s.jsx)(e.pre,{children:(0,s.jsx)(e.code,{className:"language-python",children:'import torchvision.models as models\nfrom torchvision.models import ResNet50_Weights\n\n# Transfer learning with pre-trained models\nclass TransferLearningModel(nn.Module):\n    def __init__(self, num_classes, model_name=\'resnet50\', pretrained=True):\n        super(TransferLearningModel, self).__init__()\n        \n        if model_name == \'resnet50\':\n            self.backbone = models.resnet50(weights=ResNet50_Weights.IMAGENET1K_V2 if pretrained else None)\n            num_features = self.backbone.fc.in_features\n            self.backbone.fc = nn.Linear(num_features, num_classes)\n            \n        elif model_name == \'efficientnet\':\n            self.backbone = models.efficientnet_b0(pretrained=pretrained)\n            num_features = self.backbone.classifier[1].in_features\n            self.backbone.classifier[1] = nn.Linear(num_features, num_classes)\n            \n        elif model_name == \'vit\':\n            self.backbone = models.vit_b_16(pretrained=pretrained)\n            num_features = self.backbone.heads.head.in_features\n            self.backbone.heads.head = nn.Linear(num_features, num_classes)\n    \n    def forward(self, x):\n        return self.backbone(x)\n    \n    def freeze_backbone(self):\n        """Freeze backbone parameters for feature extraction"""\n        for param in self.backbone.parameters():\n            param.requires_grad = False\n        \n        # Unfreeze classifier\n        if hasattr(self.backbone, \'fc\'):\n            for param in self.backbone.fc.parameters():\n                param.requires_grad = True\n        elif hasattr(self.backbone, \'classifier\'):\n            for param in self.backbone.classifier.parameters():\n                param.requires_grad = True\n    \n    def unfreeze_backbone(self):\n        """Unfreeze all parameters for fine-tuning"""\n        for param in self.backbone.parameters():\n            param.requires_grad = True\n\n# Object detection with YOLO-style architecture\nclass SimpleYOLO(nn.Module):\n    def __init__(self, num_classes, num_anchors=3):\n        super(SimpleYOLO, self).__init__()\n        self.num_classes = num_classes\n        self.num_anchors = num_anchors\n        \n        # Backbone\n        self.backbone = models.resnet18(pretrained=True)\n        self.backbone.fc = nn.Identity()  # Remove final FC layer\n        \n        # Detection head\n        self.conv1 = nn.Conv2d(512, 256, 3, padding=1)\n        self.conv2 = nn.Conv2d(256, 128, 3, padding=1)\n        self.conv3 = nn.Conv2d(128, num_anchors * (5 + num_classes), 1)\n        \n    def forward(self, x):\n        # Extract features\n        x = self.backbone.conv1(x)\n        x = self.backbone.bn1(x)\n        x = self.backbone.relu(x)\n        x = self.backbone.maxpool(x)\n        \n        x = self.backbone.layer1(x)\n        x = self.backbone.layer2(x)\n        x = self.backbone.layer3(x)\n        x = self.backbone.layer4(x)\n        \n        # Detection head\n        x = F.relu(self.conv1(x))\n        x = F.relu(self.conv2(x))\n        x = self.conv3(x)\n        \n        return x\n\n# Semantic segmentation with U-Net\nclass UNet(nn.Module):\n    def __init__(self, in_channels=3, num_classes=1):\n        super(UNet, self).__init__()\n        \n        # Encoder\n        self.enc1 = self.conv_block(in_channels, 64)\n        self.enc2 = self.conv_block(64, 128)\n        self.enc3 = self.conv_block(128, 256)\n        self.enc4 = self.conv_block(256, 512)\n        \n        # Bottleneck\n        self.bottleneck = self.conv_block(512, 1024)\n        \n        # Decoder\n        self.upconv4 = nn.ConvTranspose2d(1024, 512, 2, stride=2)\n        self.dec4 = self.conv_block(1024, 512)\n        \n        self.upconv3 = nn.ConvTranspose2d(512, 256, 2, stride=2)\n        self.dec3 = self.conv_block(512, 256)\n        \n        self.upconv2 = nn.ConvTranspose2d(256, 128, 2, stride=2)\n        self.dec2 = self.conv_block(256, 128)\n        \n        self.upconv1 = nn.ConvTranspose2d(128, 64, 2, stride=2)\n        self.dec1 = self.conv_block(128, 64)\n        \n        # Final layer\n        self.final = nn.Conv2d(64, num_classes, 1)\n        \n        self.pool = nn.MaxPool2d(2)\n    \n    def conv_block(self, in_channels, out_channels):\n        return nn.Sequential(\n            nn.Conv2d(in_channels, out_channels, 3, padding=1),\n            nn.BatchNorm2d(out_channels),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(out_channels, out_channels, 3, padding=1),\n            nn.BatchNorm2d(out_channels),\n            nn.ReLU(inplace=True)\n        )\n    \n    def forward(self, x):\n        # Encoder\n        enc1 = self.enc1(x)\n        enc2 = self.enc2(self.pool(enc1))\n        enc3 = self.enc3(self.pool(enc2))\n        enc4 = self.enc4(self.pool(enc3))\n        \n        # Bottleneck\n        bottleneck = self.bottleneck(self.pool(enc4))\n        \n        # Decoder\n        dec4 = self.upconv4(bottleneck)\n        dec4 = torch.cat((dec4, enc4), dim=1)\n        dec4 = self.dec4(dec4)\n        \n        dec3 = self.upconv3(dec4)\n        dec3 = torch.cat((dec3, enc3), dim=1)\n        dec3 = self.dec3(dec3)\n        \n        dec2 = self.upconv2(dec3)\n        dec2 = torch.cat((dec2, enc2), dim=1)\n        dec2 = self.dec2(dec2)\n        \n        dec1 = self.upconv1(dec2)\n        dec1 = torch.cat((dec1, enc1), dim=1)\n        dec1 = self.dec1(dec1)\n        \n        return torch.sigmoid(self.final(dec1))\n\n# Image augmentation and preprocessing\nclass AdvancedAugmentation:\n    def __init__(self):\n        self.train_transform = transforms.Compose([\n            transforms.RandomResizedCrop(224, scale=(0.8, 1.0)),\n            transforms.RandomHorizontalFlip(p=0.5),\n            transforms.RandomVerticalFlip(p=0.2),\n            transforms.RandomRotation(degrees=15),\n            transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n            transforms.RandomGrayscale(p=0.1),\n            transforms.GaussianBlur(kernel_size=3, sigma=(0.1, 2.0)),\n            transforms.ToTensor(),\n            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n            transforms.RandomErasing(p=0.2, scale=(0.02, 0.33), ratio=(0.3, 3.3))\n        ])\n        \n        self.val_transform = transforms.Compose([\n            transforms.Resize(256),\n            transforms.CenterCrop(224),\n            transforms.ToTensor(),\n            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n        ])\n\n# Example: Fine-tuning a pre-trained model\ndef fine_tune_model():\n    # Create transfer learning model\n    model = TransferLearningModel(num_classes=10, model_name=\'resnet50\', pretrained=True)\n    \n    # Phase 1: Feature extraction (freeze backbone)\n    model.freeze_backbone()\n    \n    # Setup optimizer for feature extraction\n    optimizer = optim.Adam(model.backbone.fc.parameters(), lr=0.001)\n    \n    print("Phase 1: Feature extraction training")\n    # Train for a few epochs...\n    \n    # Phase 2: Fine-tuning (unfreeze backbone)\n    model.unfreeze_backbone()\n    \n    # Setup optimizer for fine-tuning with lower learning rate\n    optimizer = optim.Adam(model.parameters(), lr=0.0001)\n    \n    print("Phase 2: Fine-tuning training")\n    # Continue training...\n    \n    return model\n\n# Test computer vision models\ntransfer_model = fine_tune_model()\nunet_model = UNet(in_channels=3, num_classes=21)  # For Pascal VOC\nyolo_model = SimpleYOLO(num_classes=80)  # For COCO\n\nprint(f"Transfer learning model parameters: {sum(p.numel() for p in transfer_model.parameters()):,}")\nprint(f"U-Net model parameters: {sum(p.numel() for p in unet_model.parameters()):,}")\nprint(f"YOLO model parameters: {sum(p.numel() for p in yolo_model.parameters()):,}")\n'})}),"\n",(0,s.jsx)(e.h2,{id:"natural-language-processing",children:"Natural Language Processing"}),"\n",(0,s.jsx)(e.h3,{id:"text-processing-and-rnntransformer-models",children:"Text Processing and RNN/Transformer Models"}),"\n",(0,s.jsx)(e.pre,{children:(0,s.jsx)(e.code,{className:"language-python",children:"import torch.nn.utils.rnn as rnn_utils\nfrom collections import Counter\nimport re\n\n# Text preprocessing utilities\nclass TextPreprocessor:\n    def __init__(self, vocab_size=10000, min_freq=2):\n        self.vocab_size = vocab_size\n        self.min_freq = min_freq\n        self.word2idx = {}\n        self.idx2word = {}\n        self.vocab = set()\n    \n    def build_vocab(self, texts):\n        # Tokenize and count words\n        word_counts = Counter()\n        for text in texts:\n            tokens = self.tokenize(text)\n            word_counts.update(tokens)\n        \n        # Build vocabulary\n        vocab_words = [word for word, count in word_counts.most_common(self.vocab_size-4) \n                      if count >= self.min_freq]\n        \n        # Special tokens\n        special_tokens = ['<PAD>', '<UNK>', '<SOS>', '<EOS>']\n        self.vocab = set(special_tokens + vocab_words)\n        \n        # Create mappings\n        self.word2idx = {word: idx for idx, word in enumerate(self.vocab)}\n        self.idx2word = {idx: word for word, idx in self.word2idx.items()}\n        \n        print(f\"Vocabulary size: {len(self.vocab)}\")\n    \n    def tokenize(self, text):\n        # Simple tokenization\n        text = text.lower()\n        text = re.sub(r'[^a-zA-Z0-9\\s]', '', text)\n        return text.split()\n    \n    def text_to_indices(self, text):\n        tokens = self.tokenize(text)\n        return [self.word2idx.get(token, self.word2idx['<UNK>']) for token in tokens]\n    \n    def indices_to_text(self, indices):\n        return ' '.join([self.idx2word.get(idx, '<UNK>') for idx in indices])\n\n# LSTM-based language model\nclass LSTMLanguageModel(nn.Module):\n    def __init__(self, vocab_size, embed_size, hidden_size, num_layers, dropout=0.2):\n        super(LSTMLanguageModel, self).__init__()\n        \n        self.vocab_size = vocab_size\n        self.embed_size = embed_size\n        self.hidden_size = hidden_size\n        self.num_layers = num_layers\n        \n        # Layers\n        self.embedding = nn.Embedding(vocab_size, embed_size)\n        self.lstm = nn.LSTM(embed_size, hidden_size, num_layers, \n                           batch_first=True, dropout=dropout)\n        self.dropout = nn.Dropout(dropout)\n        self.fc = nn.Linear(hidden_size, vocab_size)\n    \n    def forward(self, x, hidden=None):\n        # Embedding\n        embedded = self.embedding(x)\n        embedded = self.dropout(embedded)\n        \n        # LSTM\n        lstm_out, hidden = self.lstm(embedded, hidden)\n        lstm_out = self.dropout(lstm_out)\n        \n        # Output projection\n        output = self.fc(lstm_out)\n        \n        return output, hidden\n    \n    def init_hidden(self, batch_size, device):\n        h0 = torch.zeros(self.num_layers, batch_size, self.hidden_size).to(device)\n        c0 = torch.zeros(self.num_layers, batch_size, self.hidden_size).to(device)\n        return (h0, c0)\n\n# Transformer-based model\nclass TransformerModel(nn.Module):\n    def __init__(self, vocab_size, d_model, nhead, num_layers, dim_feedforward, max_seq_len, dropout=0.1):\n        super(TransformerModel, self).__init__()\n        \n        self.d_model = d_model\n        self.vocab_size = vocab_size\n        self.max_seq_len = max_seq_len\n        \n        # Embeddings\n        self.embedding = nn.Embedding(vocab_size, d_model)\n        self.pos_encoding = self.create_positional_encoding(max_seq_len, d_model)\n        \n        # Transformer\n        encoder_layer = nn.TransformerEncoderLayer(\n            d_model=d_model,\n            nhead=nhead,\n            dim_feedforward=dim_feedforward,\n            dropout=dropout,\n            batch_first=True\n        )\n        self.transformer = nn.TransformerEncoder(encoder_layer, num_layers)\n        \n        # Output layer\n        self.fc = nn.Linear(d_model, vocab_size)\n        self.dropout = nn.Dropout(dropout)\n    \n    def create_positional_encoding(self, max_seq_len, d_model):\n        pe = torch.zeros(max_seq_len, d_model)\n        position = torch.arange(0, max_seq_len).unsqueeze(1).float()\n        \n        div_term = torch.exp(torch.arange(0, d_model, 2).float() * \n                           -(torch.log(torch.tensor(10000.0)) / d_model))\n        \n        pe[:, 0::2] = torch.sin(position * div_term)\n        pe[:, 1::2] = torch.cos(position * div_term)\n        \n        return pe.unsqueeze(0)\n    \n    def forward(self, x, mask=None):\n        seq_len = x.size(1)\n        \n        # Embedding + positional encoding\n        x = self.embedding(x) * torch.sqrt(torch.tensor(self.d_model, dtype=torch.float))\n        x = x + self.pos_encoding[:, :seq_len, :].to(x.device)\n        x = self.dropout(x)\n        \n        # Transformer\n        if mask is None:\n            mask = self.generate_square_subsequent_mask(seq_len).to(x.device)\n        \n        output = self.transformer(x, mask)\n        output = self.fc(output)\n        \n        return output\n    \n    def generate_square_subsequent_mask(self, sz):\n        mask = torch.triu(torch.ones(sz, sz), diagonal=1)\n        mask = mask.masked_fill(mask == 1, float('-inf'))\n        return mask\n\n# Attention mechanism\nclass MultiHeadAttention(nn.Module):\n    def __init__(self, d_model, num_heads):\n        super(MultiHeadAttention, self).__init__()\n        assert d_model % num_heads == 0\n        \n        self.d_model = d_model\n        self.num_heads = num_heads\n        self.d_k = d_model // num_heads\n        \n        self.W_q = nn.Linear(d_model, d_model)\n        self.W_k = nn.Linear(d_model, d_model)\n        self.W_v = nn.Linear(d_model, d_model)\n        self.W_o = nn.Linear(d_model, d_model)\n        \n    def scaled_dot_product_attention(self, Q, K, V, mask=None):\n        scores = torch.matmul(Q, K.transpose(-2, -1)) / torch.sqrt(torch.tensor(self.d_k, dtype=torch.float))\n        \n        if mask is not None:\n            scores = scores.masked_fill(mask == 0, -1e9)\n        \n        attention_weights = F.softmax(scores, dim=-1)\n        output = torch.matmul(attention_weights, V)\n        \n        return output, attention_weights\n    \n    def forward(self, query, key, value, mask=None):\n        batch_size = query.size(0)\n        \n        # Linear transformations\n        Q = self.W_q(query)\n        K = self.W_k(key)\n        V = self.W_v(value)\n        \n        # Reshape for multi-head attention\n        Q = Q.view(batch_size, -1, self.num_heads, self.d_k).transpose(1, 2)\n        K = K.view(batch_size, -1, self.num_heads, self.d_k).transpose(1, 2)\n        V = V.view(batch_size, -1, self.num_heads, self.d_k).transpose(1, 2)\n        \n        # Apply attention\n        attention_output, attention_weights = self.scaled_dot_product_attention(Q, K, V, mask)\n        \n        # Concatenate heads\n        attention_output = attention_output.transpose(1, 2).contiguous().view(\n            batch_size, -1, self.d_model\n        )\n        \n        # Final linear transformation\n        output = self.W_o(attention_output)\n        \n        return output, attention_weights\n\n# Text classification model\nclass TextClassifier(nn.Module):\n    def __init__(self, vocab_size, embed_size, hidden_size, num_classes, num_layers=2):\n        super(TextClassifier, self).__init__()\n        \n        self.embedding = nn.Embedding(vocab_size, embed_size)\n        self.lstm = nn.LSTM(embed_size, hidden_size, num_layers, \n                           batch_first=True, bidirectional=True)\n        self.dropout = nn.Dropout(0.3)\n        self.fc = nn.Linear(hidden_size * 2, num_classes)  # *2 for bidirectional\n    \n    def forward(self, x):\n        # Embedding\n        embedded = self.embedding(x)\n        \n        # LSTM\n        lstm_out, (hidden, _) = self.lstm(embedded)\n        \n        # Use last hidden state from both directions\n        hidden = torch.cat((hidden[-2], hidden[-1]), dim=1)\n        hidden = self.dropout(hidden)\n        \n        # Classification\n        output = self.fc(hidden)\n        \n        return output\n\n# Example usage\ndef train_nlp_model():\n    # Sample data\n    texts = [\n        \"This is a sample sentence for training.\",\n        \"Natural language processing with PyTorch is powerful.\",\n        \"Deep learning models can understand text patterns.\"\n    ]\n    \n    # Preprocess text\n    preprocessor = TextPreprocessor(vocab_size=1000)\n    preprocessor.build_vocab(texts)\n    \n    # Create models\n    vocab_size = len(preprocessor.vocab)\n    \n    # LSTM Language Model\n    lstm_model = LSTMLanguageModel(\n        vocab_size=vocab_size,\n        embed_size=128,\n        hidden_size=256,\n        num_layers=2\n    )\n    \n    # Transformer Model\n    transformer_model = TransformerModel(\n        vocab_size=vocab_size,\n        d_model=128,\n        nhead=8,\n        num_layers=6,\n        dim_feedforward=512,\n        max_seq_len=100\n    )\n    \n    # Text Classifier\n    classifier_model = TextClassifier(\n        vocab_size=vocab_size,\n        embed_size=128,\n        hidden_size=256,\n        num_classes=3\n    )\n    \n    print(f\"LSTM model parameters: {sum(p.numel() for p in lstm_model.parameters()):,}\")\n    print(f\"Transformer model parameters: {sum(p.numel() for p in transformer_model.parameters()):,}\")\n    print(f\"Classifier model parameters: {sum(p.numel() for p in classifier_model.parameters()):,}\")\n    \n    return lstm_model, transformer_model, classifier_model\n\n# Test NLP models\nlstm_model, transformer_model, classifier_model = train_nlp_model()\n"})}),"\n",(0,s.jsx)(e.h2,{id:"advanced-topics",children:"Advanced Topics"}),"\n",(0,s.jsx)(e.h3,{id:"custom-loss-functions-and-metrics",children:"Custom Loss Functions and Metrics"}),"\n",(0,s.jsx)(e.pre,{children:(0,s.jsx)(e.code,{className:"language-python",children:"# Custom loss functions\nclass FocalLoss(nn.Module):\n    def __init__(self, alpha=1, gamma=2, reduction='mean'):\n        super(FocalLoss, self).__init__()\n        self.alpha = alpha\n        self.gamma = gamma\n        self.reduction = reduction\n    \n    def forward(self, inputs, targets):\n        ce_loss = F.cross_entropy(inputs, targets, reduction='none')\n        pt = torch.exp(-ce_loss)\n        focal_loss = self.alpha * (1 - pt) ** self.gamma * ce_loss\n        \n        if self.reduction == 'mean':\n            return focal_loss.mean()\n        elif self.reduction == 'sum':\n            return focal_loss.sum()\n        else:\n            return focal_loss\n\nclass DiceLoss(nn.Module):\n    def __init__(self, smooth=1):\n        super(DiceLoss, self).__init__()\n        self.smooth = smooth\n    \n    def forward(self, inputs, targets):\n        inputs = torch.sigmoid(inputs)\n        \n        # Flatten tensors\n        inputs = inputs.view(-1)\n        targets = targets.view(-1)\n        \n        intersection = (inputs * targets).sum()\n        dice = (2. * intersection + self.smooth) / (inputs.sum() + targets.sum() + self.smooth)\n        \n        return 1 - dice\n\nclass ContrastiveLoss(nn.Module):\n    def __init__(self, margin=2.0):\n        super(ContrastiveLoss, self).__init__()\n        self.margin = margin\n    \n    def forward(self, output1, output2, label):\n        euclidean_distance = F.pairwise_distance(output1, output2)\n        loss_contrastive = torch.mean((1 - label) * torch.pow(euclidean_distance, 2) +\n                                    label * torch.pow(torch.clamp(self.margin - euclidean_distance, min=0.0), 2))\n        return loss_contrastive\n\n# Custom metrics\nclass MetricsCalculator:\n    def __init__(self, num_classes):\n        self.num_classes = num_classes\n        self.reset()\n    \n    def reset(self):\n        self.confusion_matrix = torch.zeros(self.num_classes, self.num_classes)\n        self.total_samples = 0\n        self.correct_predictions = 0\n    \n    def update(self, predictions, targets):\n        _, predicted = torch.max(predictions, 1)\n        self.total_samples += targets.size(0)\n        self.correct_predictions += (predicted == targets).sum().item()\n        \n        # Update confusion matrix\n        for t, p in zip(targets.view(-1), predicted.view(-1)):\n            self.confusion_matrix[t.long(), p.long()] += 1\n    \n    def accuracy(self):\n        return self.correct_predictions / self.total_samples\n    \n    def precision(self, class_idx=None):\n        if class_idx is not None:\n            tp = self.confusion_matrix[class_idx, class_idx]\n            fp = self.confusion_matrix[:, class_idx].sum() - tp\n            return tp / (tp + fp) if (tp + fp) > 0 else 0\n        else:\n            precisions = []\n            for i in range(self.num_classes):\n                precisions.append(self.precision(i))\n            return sum(precisions) / len(precisions)\n    \n    def recall(self, class_idx=None):\n        if class_idx is not None:\n            tp = self.confusion_matrix[class_idx, class_idx]\n            fn = self.confusion_matrix[class_idx, :].sum() - tp\n            return tp / (tp + fn) if (tp + fn) > 0 else 0\n        else:\n            recalls = []\n            for i in range(self.num_classes):\n                recalls.append(self.recall(i))\n            return sum(recalls) / len(recalls)\n    \n    def f1_score(self, class_idx=None):\n        if class_idx is not None:\n            p = self.precision(class_idx)\n            r = self.recall(class_idx)\n            return 2 * p * r / (p + r) if (p + r) > 0 else 0\n        else:\n            f1_scores = []\n            for i in range(self.num_classes):\n                f1_scores.append(self.f1_score(i))\n            return sum(f1_scores) / len(f1_scores)\n\n# Model interpretability\nclass GradCAM:\n    def __init__(self, model, target_layer):\n        self.model = model\n        self.target_layer = target_layer\n        self.gradients = None\n        self.activations = None\n        \n        # Register hooks\n        self.target_layer.register_forward_hook(self.save_activation)\n        self.target_layer.register_backward_hook(self.save_gradient)\n    \n    def save_activation(self, module, input, output):\n        self.activations = output\n    \n    def save_gradient(self, module, grad_input, grad_output):\n        self.gradients = grad_output[0]\n    \n    def generate_cam(self, input_image, class_idx):\n        # Forward pass\n        output = self.model(input_image)\n        \n        # Backward pass\n        self.model.zero_grad()\n        class_loss = output[0, class_idx]\n        class_loss.backward()\n        \n        # Generate CAM\n        gradients = self.gradients[0]\n        activations = self.activations[0]\n        \n        weights = torch.mean(gradients, dim=(1, 2))\n        cam = torch.zeros(activations.shape[1:], dtype=torch.float32)\n        \n        for i, w in enumerate(weights):\n            cam += w * activations[i]\n        \n        cam = F.relu(cam)\n        cam = cam / torch.max(cam)\n        \n        return cam\n\n# Regularization techniques\nclass DropBlock2D(nn.Module):\n    def __init__(self, drop_rate, block_size):\n        super(DropBlock2D, self).__init__()\n        self.drop_rate = drop_rate\n        self.block_size = block_size\n    \n    def forward(self, x):\n        if not self.training:\n            return x\n        \n        gamma = self.drop_rate / (self.block_size ** 2)\n        mask = (torch.rand(x.shape[0], *x.shape[2:]) < gamma).float()\n        \n        # Expand mask\n        mask = mask.unsqueeze(1)\n        mask = F.max_pool2d(mask, (self.block_size, self.block_size), \n                           stride=(1, 1), padding=self.block_size // 2)\n        \n        mask = 1 - mask\n        normalize_factor = mask.numel() / mask.sum()\n        \n        return x * mask * normalize_factor\n\nclass MixUp:\n    def __init__(self, alpha=1.0):\n        self.alpha = alpha\n    \n    def __call__(self, x, y):\n        if self.alpha > 0:\n            lam = np.random.beta(self.alpha, self.alpha)\n        else:\n            lam = 1\n        \n        batch_size = x.size(0)\n        index = torch.randperm(batch_size)\n        \n        mixed_x = lam * x + (1 - lam) * x[index, :]\n        y_a, y_b = y, y[index]\n        \n        return mixed_x, y_a, y_b, lam\n\n# Knowledge distillation\nclass DistillationLoss(nn.Module):\n    def __init__(self, alpha=0.5, temperature=4):\n        super(DistillationLoss, self).__init__()\n        self.alpha = alpha\n        self.temperature = temperature\n        self.kl_div = nn.KLDivLoss(reduction='batchmean')\n        self.ce_loss = nn.CrossEntropyLoss()\n    \n    def forward(self, student_outputs, teacher_outputs, targets):\n        # Soft targets from teacher\n        soft_targets = F.softmax(teacher_outputs / self.temperature, dim=1)\n        soft_student = F.log_softmax(student_outputs / self.temperature, dim=1)\n        \n        # Distillation loss\n        distillation_loss = self.kl_div(soft_student, soft_targets) * (self.temperature ** 2)\n        \n        # Student loss\n        student_loss = self.ce_loss(student_outputs, targets)\n        \n        # Combined loss\n        total_loss = self.alpha * distillation_loss + (1 - self.alpha) * student_loss\n        \n        return total_loss\n\n# Example usage of advanced techniques\ndef advanced_training_example():\n    # Create model\n    model = CNN(num_classes=10)\n    \n    # Custom loss\n    focal_loss = FocalLoss(alpha=1, gamma=2)\n    \n    # Metrics calculator\n    metrics = MetricsCalculator(num_classes=10)\n    \n    # MixUp augmentation\n    mixup = MixUp(alpha=1.0)\n    \n    # Training loop with advanced techniques\n    model.train()\n    for batch_idx, (data, target) in enumerate(train_loader):\n        # Apply MixUp\n        mixed_data, target_a, target_b, lam = mixup(data, target)\n        \n        # Forward pass\n        output = model(mixed_data)\n        \n        # Calculate loss with MixUp\n        loss = lam * focal_loss(output, target_a) + (1 - lam) * focal_loss(output, target_b)\n        \n        # Update metrics\n        metrics.update(output, target)\n        \n        # Backward pass\n        loss.backward()\n        \n        if batch_idx % 100 == 0:\n            print(f'Batch {batch_idx}, Loss: {loss.item():.4f}')\n            print(f'Accuracy: {metrics.accuracy():.4f}')\n            print(f'F1 Score: {metrics.f1_score():.4f}')\n\n# Test advanced techniques\nadvanced_training_example()\n"})}),"\n",(0,s.jsx)(e.h2,{id:"production-deployment",children:"Production Deployment"}),"\n",(0,s.jsx)(e.h3,{id:"model-optimization-and-deployment",children:"Model Optimization and Deployment"}),"\n",(0,s.jsx)(e.pre,{children:(0,s.jsx)(e.code,{className:"language-python",children:"# Model optimization techniques\ndef optimize_model_for_inference(model, example_input):\n    \"\"\"Optimize model for inference\"\"\"\n    \n    # 1. Set to evaluation mode\n    model.eval()\n    \n    # 2. Trace the model\n    traced_model = torch.jit.trace(model, example_input)\n    \n    # 3. Optimize for inference\n    traced_model = torch.jit.optimize_for_inference(traced_model)\n    \n    # 4. Save optimized model\n    traced_model.save('optimized_model.pt')\n    \n    return traced_model\n\n# Quantization\ndef quantize_model(model, data_loader):\n    \"\"\"Apply post-training quantization\"\"\"\n    \n    # Prepare model for quantization\n    model.eval()\n    model_fp32 = model\n    model_fp32.qconfig = torch.quantization.get_default_qconfig('fbgemm')\n    \n    # Prepare model\n    model_fp32_prepared = torch.quantization.prepare(model_fp32)\n    \n    # Calibrate with representative data\n    with torch.no_grad():\n        for data, _ in data_loader:\n            model_fp32_prepared(data)\n            break  # Use only one batch for calibration\n    \n    # Convert to quantized model\n    model_int8 = torch.quantization.convert(model_fp32_prepared)\n    \n    return model_int8\n\n# ONNX export\ndef export_to_onnx(model, example_input, onnx_path):\n    \"\"\"Export model to ONNX format\"\"\"\n    \n    model.eval()\n    \n    torch.onnx.export(\n        model,\n        example_input,\n        onnx_path,\n        export_params=True,\n        opset_version=11,\n        do_constant_folding=True,\n        input_names=['input'],\n        output_names=['output'],\n        dynamic_axes={\n            'input': {0: 'batch_size'},\n            'output': {0: 'batch_size'}\n        }\n    )\n    \n    print(f\"Model exported to {onnx_path}\")\n\n# TensorRT optimization (requires TensorRT)\ndef optimize_with_tensorrt(onnx_path, trt_path):\n    \"\"\"Optimize ONNX model with TensorRT\"\"\"\n    try:\n        import tensorrt as trt\n        \n        logger = trt.Logger(trt.Logger.WARNING)\n        builder = trt.Builder(logger)\n        network = builder.create_network(1 << int(trt.NetworkDefinitionCreationFlag.EXPLICIT_BATCH))\n        parser = trt.OnnxParser(network, logger)\n        \n        # Parse ONNX model\n        with open(onnx_path, 'rb') as model:\n            if not parser.parse(model.read()):\n                for error in range(parser.num_errors):\n                    print(parser.get_error(error))\n                return None\n        \n        # Build engine\n        config = builder.create_builder_config()\n        config.max_workspace_size = 1 << 30  # 1GB\n        config.set_flag(trt.BuilderFlag.FP16)  # Enable FP16 precision\n        \n        engine = builder.build_engine(network, config)\n        \n        # Save engine\n        with open(trt_path, 'wb') as f:\n            f.write(engine.serialize())\n        \n        print(f\"TensorRT engine saved to {trt_path}\")\n        return engine\n        \n    except ImportError:\n        print(\"TensorRT not available\")\n        return None\n\n# Model serving with Flask\nfrom flask import Flask, request, jsonify\nimport base64\nfrom PIL import Image\nimport io\n\nclass ModelServer:\n    def __init__(self, model_path, device='cpu'):\n        self.device = device\n        self.model = torch.jit.load(model_path, map_location=device)\n        self.model.eval()\n        \n        # Define preprocessing\n        self.transform = transforms.Compose([\n            transforms.Resize(224),\n            transforms.CenterCrop(224),\n            transforms.ToTensor(),\n            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n        ])\n    \n    def predict(self, image):\n        # Preprocess image\n        if isinstance(image, str):  # Base64 encoded\n            image_data = base64.b64decode(image)\n            image = Image.open(io.BytesIO(image_data)).convert('RGB')\n        \n        input_tensor = self.transform(image).unsqueeze(0).to(self.device)\n        \n        # Inference\n        with torch.no_grad():\n            output = self.model(input_tensor)\n            probabilities = F.softmax(output, dim=1)\n            predicted_class = torch.argmax(probabilities, dim=1).item()\n            confidence = probabilities[0][predicted_class].item()\n        \n        return {\n            'predicted_class': predicted_class,\n            'confidence': confidence,\n            'probabilities': probabilities[0].tolist()\n        }\n\n# Flask app\napp = Flask(__name__)\nmodel_server = ModelServer('optimized_model.pt')\n\n@app.route('/predict', methods=['POST'])\ndef predict():\n    try:\n        data = request.json\n        image_data = data['image']\n        \n        result = model_server.predict(image_data)\n        return jsonify(result)\n    \n    except Exception as e:\n        return jsonify({'error': str(e)}), 400\n\n@app.route('/health', methods=['GET'])\ndef health():\n    return jsonify({'status': 'healthy'})\n\n# Batch inference optimization\nclass BatchInferenceEngine:\n    def __init__(self, model_path, batch_size=32, device='cuda'):\n        self.model = torch.jit.load(model_path, map_location=device)\n        self.model.eval()\n        self.batch_size = batch_size\n        self.device = device\n        self.pending_requests = []\n    \n    def add_request(self, image, request_id):\n        self.pending_requests.append((image, request_id))\n        \n        if len(self.pending_requests) >= self.batch_size:\n            return self.process_batch()\n        return None\n    \n    def process_batch(self):\n        if not self.pending_requests:\n            return []\n        \n        # Prepare batch\n        images = []\n        request_ids = []\n        \n        for image, request_id in self.pending_requests:\n            images.append(image)\n            request_ids.append(request_id)\n        \n        # Convert to tensor\n        batch_tensor = torch.stack(images).to(self.device)\n        \n        # Inference\n        with torch.no_grad():\n            outputs = self.model(batch_tensor)\n            probabilities = F.softmax(outputs, dim=1)\n        \n        # Prepare results\n        results = []\n        for i, request_id in enumerate(request_ids):\n            predicted_class = torch.argmax(probabilities[i]).item()\n            confidence = probabilities[i][predicted_class].item()\n            \n            results.append({\n                'request_id': request_id,\n                'predicted_class': predicted_class,\n                'confidence': confidence\n            })\n        \n        # Clear pending requests\n        self.pending_requests = []\n        \n        return results\n\n# Performance monitoring\nclass PerformanceMonitor:\n    def __init__(self):\n        self.inference_times = []\n        self.memory_usage = []\n        self.throughput = []\n    \n    def log_inference(self, inference_time, memory_used, batch_size):\n        self.inference_times.append(inference_time)\n        self.memory_usage.append(memory_used)\n        self.throughput.append(batch_size / inference_time)\n    \n    def get_stats(self):\n        if not self.inference_times:\n            return {}\n        \n        return {\n            'avg_inference_time': np.mean(self.inference_times),\n            'p95_inference_time': np.percentile(self.inference_times, 95),\n            'avg_memory_usage': np.mean(self.memory_usage),\n            'avg_throughput': np.mean(self.throughput),\n            'total_requests': len(self.inference_times)\n        }\n\n# Example deployment workflow\ndef deployment_workflow():\n    # 1. Load trained model\n    model = CNN(num_classes=10)\n    model.load_state_dict(torch.load('best_model.pth'))\n    \n    # 2. Create example input\n    example_input = torch.randn(1, 3, 224, 224)\n    \n    # 3. Optimize model\n    optimized_model = optimize_model_for_inference(model, example_input)\n    \n    # 4. Quantize model (optional)\n    # quantized_model = quantize_model(model, val_loader)\n    \n    # 5. Export to ONNX\n    export_to_onnx(optimized_model, example_input, 'model.onnx')\n    \n    # 6. Optimize with TensorRT (optional)\n    # optimize_with_tensorrt('model.onnx', 'model.trt')\n    \n    # 7. Test inference\n    test_inference_performance(optimized_model, example_input)\n    \n    print(\"Deployment workflow completed!\")\n\ndef test_inference_performance(model, example_input, num_runs=100):\n    \"\"\"Test inference performance\"\"\"\n    model.eval()\n    \n    # Warmup\n    for _ in range(10):\n        with torch.no_grad():\n            _ = model(example_input)\n    \n    # Measure performance\n    start_time = time.time()\n    \n    for _ in range(num_runs):\n        with torch.no_grad():\n            _ = model(example_input)\n    \n    end_time = time.time()\n    \n    avg_time = (end_time - start_time) / num_runs\n    throughput = 1 / avg_time\n    \n    print(f\"Average inference time: {avg_time*1000:.2f} ms\")\n    print(f\"Throughput: {throughput:.2f} inferences/second\")\n\n# Run deployment workflow\ndeployment_workflow()\n\nif __name__ == '__main__':\n    # Start Flask server\n    app.run(host='0.0.0.0', port=5000, debug=False)\n"})}),"\n",(0,s.jsx)(e.h2,{id:"troubleshooting",children:"Troubleshooting"}),"\n",(0,s.jsx)(e.p,{children:"Common issues and solutions for PyTorch development."}),"\n",(0,s.jsx)(e.h3,{id:"1-cuda-out-of-memory-error",children:"1. CUDA Out of Memory Error"}),"\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"Error:"})}),"\n",(0,s.jsx)(e.pre,{children:(0,s.jsx)(e.code,{children:"RuntimeError: CUDA out of memory. Tried to allocate X MiB\n"})}),"\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"Solutions:"})}),"\n",(0,s.jsx)(e.pre,{children:(0,s.jsx)(e.code,{className:"language-python",children:"# Solution 1: Reduce batch size\ntrain_loader = DataLoader(dataset, batch_size=16, shuffle=True)  # Instead of 64\n\n# Solution 2: Use gradient accumulation\naccumulation_steps = 4\noptimizer.zero_grad()\n\nfor i, (inputs, targets) in enumerate(train_loader):\n    outputs = model(inputs)\n    loss = criterion(outputs, targets) / accumulation_steps\n    loss.backward()\n\n    if (i + 1) % accumulation_steps == 0:\n        optimizer.step()\n        optimizer.zero_grad()\n\n# Solution 3: Clear cache regularly\nimport torch\ntorch.cuda.empty_cache()\n\n# Solution 4: Use mixed precision training\nfrom torch.cuda.amp import autocast, GradScaler\nscaler = GradScaler()\n\nwith autocast():\n    outputs = model(inputs)\n    loss = criterion(outputs, targets)\n\n# Solution 5: Enable gradient checkpointing for large models\nfrom torch.utils.checkpoint import checkpoint\n\nclass CheckpointedModel(nn.Module):\n    def forward(self, x):\n        x = checkpoint(self.layer1, x)\n        x = checkpoint(self.layer2, x)\n        return x\n"})}),"\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"Prevention:"})}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsxs)(e.li,{children:["Monitor GPU memory usage: ",(0,s.jsx)(e.code,{children:"torch.cuda.memory_allocated()"}),", ",(0,s.jsx)(e.code,{children:"torch.cuda.memory_reserved()"})]}),"\n",(0,s.jsx)(e.li,{children:"Use smaller batch sizes for training"}),"\n",(0,s.jsx)(e.li,{children:"Consider using gradient accumulation"}),"\n",(0,s.jsxs)(e.li,{children:["Delete unused variables with ",(0,s.jsx)(e.code,{children:"del variable"})]}),"\n"]}),"\n",(0,s.jsx)(e.h3,{id:"2-pytorch-installation-issues",children:"2. PyTorch Installation Issues"}),"\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"Error:"})}),"\n",(0,s.jsx)(e.pre,{children:(0,s.jsx)(e.code,{children:"No module named 'torch'\nImportError: cannot import name 'torch'\n"})}),"\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"Solutions:"})}),"\n",(0,s.jsx)(e.pre,{children:(0,s.jsx)(e.code,{className:"language-bash",children:"# Solution 1: Verify Python version (requires 3.8+)\npython --version\n\n# Solution 2: Install PyTorch with correct CUDA version\n# Check CUDA version first\nnvidia-smi\n\n# Install matching PyTorch version\npip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\n\n# Solution 3: Use conda for easier dependency management\nconda create -n pytorch_env python=3.10\nconda activate pytorch_env\nconda install pytorch torchvision torchaudio pytorch-cuda=11.8 -c pytorch -c nvidia\n\n# Solution 4: Install CPU-only version if GPU not available\npip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cpu\n\n# Solution 5: Clear pip cache if installation corrupted\npip cache purge\npip uninstall torch torchvision torchaudio\npip install torch torchvision torchaudio\n"})}),"\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"Verification:"})}),"\n",(0,s.jsx)(e.pre,{children:(0,s.jsx)(e.code,{className:"language-python",children:'import torch\nprint(f"PyTorch version: {torch.__version__}")\nprint(f"CUDA available: {torch.cuda.is_available()}")\nprint(f"CUDA version: {torch.version.cuda}")\n'})}),"\n",(0,s.jsx)(e.h3,{id:"3-version-compatibility-errors",children:"3. Version Compatibility Errors"}),"\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"Error:"})}),"\n",(0,s.jsx)(e.pre,{children:(0,s.jsx)(e.code,{children:"AttributeError: module 'torch' has no attribute 'XXX'\nRuntimeError: Trying to backward through the graph a second time\n"})}),"\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"Solutions:"})}),"\n",(0,s.jsx)(e.pre,{children:(0,s.jsx)(e.code,{className:"language-python",children:"# Solution 1: Check PyTorch version compatibility\nimport torch\nprint(torch.__version__)\n\n# For PyTorch 2.0+, use torch.compile\nmodel = torch.compile(model)  # Only available in PyTorch 2.0+\n\n# For older versions, use different syntax\nif torch.__version__ >= '2.0':\n    model = torch.compile(model)\nelse:\n    # Use alternative optimization\n\n# Solution 2: Fix backward computation\n# Don't call backward() twice on same graph\nloss = criterion(outputs, targets)\nloss.backward()  # Call only once\n\n# If you need to compute gradients twice, use retain_graph=True\nloss1.backward(retain_graph=True)\nloss2.backward()\n\n# Solution 3: Upgrade PyTorch to latest stable version\npip install --upgrade torch torchvision torchaudio\n\n# Solution 4: Use version-specific imports\ntry:\n    from torch.cuda.amp import autocast, GradScaler\nexcept ImportError:\n    # Fallback for older versions\n    autocast = None\n    GradScaler = None\n"})}),"\n",(0,s.jsx)(e.h3,{id:"4-dataloader-worker-errors",children:"4. DataLoader Worker Errors"}),"\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"Error:"})}),"\n",(0,s.jsx)(e.pre,{children:(0,s.jsx)(e.code,{children:"RuntimeError: DataLoader worker is killed by signal\nRuntimeError: Too many open files\nBrokenPipeError: [Errno 32] Broken pipe\n"})}),"\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"Solutions:"})}),"\n",(0,s.jsx)(e.pre,{children:(0,s.jsx)(e.code,{className:"language-python",children:"# Solution 1: Reduce number of workers\ntrain_loader = DataLoader(\n    dataset,\n    batch_size=32,\n    num_workers=0,  # Start with 0, then gradually increase\n    pin_memory=True\n)\n\n# Solution 2: Increase system file limit (Unix/Linux)\nimport resource\nsoft, hard = resource.getrlimit(resource.RLIMIT_NOFILE)\nresource.setrlimit(resource.RLIMIT_NOFILE, (hard, hard))\n\n# Solution 3: Use persistent workers (PyTorch 1.7+)\ntrain_loader = DataLoader(\n    dataset,\n    batch_size=32,\n    num_workers=4,\n    persistent_workers=True  # Keep workers alive between epochs\n)\n\n# Solution 4: Fix multiprocessing on Windows\nif __name__ == '__main__':\n    train_loader = DataLoader(dataset, num_workers=2)\n    for data in train_loader:\n        pass\n\n# Solution 5: Handle shared memory properly\ntrain_loader = DataLoader(\n    dataset,\n    batch_size=32,\n    num_workers=2,\n    pin_memory=False  # Disable if causing issues\n)\n"})}),"\n",(0,s.jsx)(e.h3,{id:"5-model-device-mismatch",children:"5. Model Device Mismatch"}),"\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"Error:"})}),"\n",(0,s.jsx)(e.pre,{children:(0,s.jsx)(e.code,{children:"RuntimeError: Expected all tensors to be on the same device\nRuntimeError: Input type (torch.FloatTensor) and weight type (torch.cuda.FloatTensor) should be the same\n"})}),"\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"Solutions:"})}),"\n",(0,s.jsx)(e.pre,{children:(0,s.jsx)(e.code,{className:"language-python",children:"# Solution 1: Move all tensors to same device\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n\nmodel = model.to(device)\ninputs = inputs.to(device)\ntargets = targets.to(device)\n\n# Solution 2: Create helper function\ndef to_device(data, device):\n    \"\"\"Move tensor or list of tensors to device\"\"\"\n    if isinstance(data, (list, tuple)):\n        return [to_device(x, device) for x in data]\n    return data.to(device, non_blocking=True)\n\n# Usage\ninputs, targets = to_device((inputs, targets), device)\n\n# Solution 3: Check device before operations\ndef forward(self, x):\n    # Ensure input is on correct device\n    if x.device != self.weight.device:\n        x = x.to(self.weight.device)\n    return self.linear(x)\n\n# Solution 4: Use consistent device throughout\nclass Model(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n        self.layer = nn.Linear(10, 5).to(self.device)\n\n    def forward(self, x):\n        x = x.to(self.device)\n        return self.layer(x)\n"})}),"\n",(0,s.jsx)(e.h3,{id:"6-gradient-computation-errors",children:"6. Gradient Computation Errors"}),"\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"Error:"})}),"\n",(0,s.jsx)(e.pre,{children:(0,s.jsx)(e.code,{children:"RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\nRuntimeError: One of the differentiated Tensors appears to not have been used in the graph\n"})}),"\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"Solutions:"})}),"\n",(0,s.jsx)(e.pre,{children:(0,s.jsx)(e.code,{className:"language-python",children:'# Solution 1: Enable gradient tracking\nx = torch.randn(3, 3, requires_grad=True)  # Enable gradients\n\n# Solution 2: Check model parameters require gradients\nfor name, param in model.named_parameters():\n    print(f"{name}: requires_grad={param.requires_grad}")\n\n# Solution 3: Don\'t detach tensors needed for backward\n# Wrong: loss = loss.detach()\n# Right: loss = criterion(outputs, targets)\n\n# Solution 4: Use torch.no_grad() for inference only\nwith torch.no_grad():\n    outputs = model(inputs)  # No gradient computation\n\n# Solution 5: Fix custom loss functions\nclass CustomLoss(nn.Module):\n    def forward(self, predictions, targets):\n        # Make sure to return a tensor with grad_fn\n        loss = torch.mean((predictions - targets) ** 2)\n        return loss  # Not loss.item() or loss.detach()\n\n# Solution 6: Avoid in-place operations on tensors requiring gradients\n# Wrong: x += 1  (in-place)\n# Right: x = x + 1  (out-of-place)\n'})}),"\n",(0,s.jsx)(e.h3,{id:"7-import-and-module-errors",children:"7. Import and Module Errors"}),"\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"Error:"})}),"\n",(0,s.jsx)(e.pre,{children:(0,s.jsx)(e.code,{children:"ModuleNotFoundError: No module named 'torchvision'\nImportError: cannot import name 'DataLoader'\nAttributeError: module has no attribute\n"})}),"\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"Solutions:"})}),"\n",(0,s.jsx)(e.pre,{children:(0,s.jsx)(e.code,{className:"language-bash",children:'# Solution 1: Install missing packages\npip install torchvision torchaudio\npip install scikit-learn matplotlib numpy pandas\n\n# Solution 2: Check correct import paths\n# Correct imports\nfrom torch.utils.data import DataLoader, Dataset\nfrom torchvision import transforms, datasets\nfrom torch import nn, optim\nimport torch.nn.functional as F\n\n# Solution 3: Verify package installation\npython -c "import torch; import torchvision; print(\'All imports successful\')"\n\n# Solution 4: Use virtual environment to avoid conflicts\npython -m venv pytorch_env\nsource pytorch_env/bin/activate  # On Unix\n# or\npytorch_env\\Scripts\\activate  # On Windows\n\npip install torch torchvision torchaudio\n\n# Solution 5: Fix PYTHONPATH issues\nexport PYTHONPATH="${PYTHONPATH}:/path/to/your/project"\n'})}),"\n",(0,s.jsx)(e.h3,{id:"8-training-performance-issues",children:"8. Training Performance Issues"}),"\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"Error:"})}),"\n",(0,s.jsx)(e.pre,{children:(0,s.jsx)(e.code,{children:"Training is too slow\nGPU utilization is low\n"})}),"\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"Solutions:"})}),"\n",(0,s.jsx)(e.pre,{children:(0,s.jsx)(e.code,{className:"language-python",children:"# Solution 1: Use mixed precision training\nfrom torch.cuda.amp import autocast, GradScaler\n\nscaler = GradScaler()\n\nfor inputs, targets in train_loader:\n    optimizer.zero_grad()\n\n    with autocast():  # Automatic mixed precision\n        outputs = model(inputs)\n        loss = criterion(outputs, targets)\n\n    scaler.scale(loss).backward()\n    scaler.step(optimizer)\n    scaler.update()\n\n# Solution 2: Optimize DataLoader\ntrain_loader = DataLoader(\n    dataset,\n    batch_size=64,  # Larger batch size\n    num_workers=4,  # Parallel data loading\n    pin_memory=True,  # Faster data transfer to GPU\n    prefetch_factor=2,  # Pre-load batches\n    persistent_workers=True  # Keep workers alive\n)\n\n# Solution 3: Use gradient accumulation for larger effective batch size\naccumulation_steps = 4\nfor i, (inputs, targets) in enumerate(train_loader):\n    outputs = model(inputs)\n    loss = criterion(outputs, targets) / accumulation_steps\n    loss.backward()\n\n    if (i + 1) % accumulation_steps == 0:\n        optimizer.step()\n        optimizer.zero_grad()\n\n# Solution 4: Compile model (PyTorch 2.0+)\nmodel = torch.compile(model, mode='max-autotune')\n\n# Solution 5: Use channels_last memory format for CNNs\nmodel = model.to(memory_format=torch.channels_last)\ninputs = inputs.to(memory_format=torch.channels_last)\n\n# Solution 6: Profile your code\nfrom torch.profiler import profile, ProfilerActivity\n\nwith profile(activities=[ProfilerActivity.CPU, ProfilerActivity.CUDA]) as prof:\n    outputs = model(inputs)\n\nprint(prof.key_averages().table(sort_by=\"cuda_time_total\"))\n"})}),"\n",(0,s.jsx)(e.h3,{id:"9-model-saving-and-loading-issues",children:"9. Model Saving and Loading Issues"}),"\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"Error:"})}),"\n",(0,s.jsx)(e.pre,{children:(0,s.jsx)(e.code,{children:"RuntimeError: Error(s) in loading state_dict\nFileNotFoundError: No such file or directory\n"})}),"\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"Solutions:"})}),"\n",(0,s.jsx)(e.pre,{children:(0,s.jsx)(e.code,{className:"language-python",children:"# Solution 1: Save and load correctly\n# Save model\ntorch.save(model.state_dict(), 'model.pth')\n\n# Load model\nmodel = MyModel()\nmodel.load_state_dict(torch.load('model.pth'))\nmodel.eval()\n\n# Solution 2: Save with optimizer and epoch info\ncheckpoint = {\n    'epoch': epoch,\n    'model_state_dict': model.state_dict(),\n    'optimizer_state_dict': optimizer.state_dict(),\n    'loss': loss,\n}\ntorch.save(checkpoint, 'checkpoint.pth')\n\n# Load checkpoint\ncheckpoint = torch.load('checkpoint.pth')\nmodel.load_state_dict(checkpoint['model_state_dict'])\noptimizer.load_state_dict(checkpoint['optimizer_state_dict'])\nepoch = checkpoint['epoch']\nloss = checkpoint['loss']\n\n# Solution 3: Handle device mapping\n# When loading on different device\nmodel.load_state_dict(torch.load('model.pth', map_location='cpu'))\n\n# Solution 4: Load partial state dict\nstate_dict = torch.load('model.pth')\nmodel.load_state_dict(state_dict, strict=False)  # Ignore missing keys\n\n# Solution 5: Use safeguards for file paths\nimport os\nmodel_path = 'model.pth'\nif os.path.exists(model_path):\n    model.load_state_dict(torch.load(model_path))\nelse:\n    print(f\"Model file {model_path} not found\")\n"})}),"\n",(0,s.jsx)(e.h3,{id:"10-distributed-training-errors",children:"10. Distributed Training Errors"}),"\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"Error:"})}),"\n",(0,s.jsx)(e.pre,{children:(0,s.jsx)(e.code,{children:"RuntimeError: NCCL error\nRuntimeError: Default process group has not been initialized\n"})}),"\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"Solutions:"})}),"\n",(0,s.jsx)(e.pre,{children:(0,s.jsx)(e.code,{className:"language-python",children:"# Solution 1: Initialize distributed training properly\nimport torch.distributed as dist\nimport torch.multiprocessing as mp\n\ndef setup(rank, world_size):\n    os.environ['MASTER_ADDR'] = 'localhost'\n    os.environ['MASTER_PORT'] = '12355'\n    dist.init_process_group(\"nccl\", rank=rank, world_size=world_size)\n\ndef cleanup():\n    dist.destroy_process_group()\n\ndef train(rank, world_size):\n    setup(rank, world_size)\n\n    model = MyModel().to(rank)\n    model = nn.parallel.DistributedDataParallel(model, device_ids=[rank])\n\n    # Training loop\n\n    cleanup()\n\n# Solution 2: Use torchrun for launching\n# Save as train.py, then run:\n# torchrun --nproc_per_node=2 train.py\n\n# Solution 3: Handle NCCL timeouts\nos.environ['NCCL_TIMEOUT'] = '1800'  # 30 minutes\nos.environ['NCCL_DEBUG'] = 'INFO'\n\n# Solution 4: Use DataParallel for single machine multi-GPU\nif torch.cuda.device_count() > 1:\n    model = nn.DataParallel(model)\n\n# Solution 5: Debug distributed training\ndef print_rank_0(message):\n    if dist.get_rank() == 0:\n        print(message)\n\n# Use for debugging\nprint_rank_0(f\"Training step {step}\")\n"})}),"\n",(0,s.jsx)(e.h3,{id:"additional-troubleshooting-resources",children:"Additional Troubleshooting Resources"}),"\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"Check GPU Status:"})}),"\n",(0,s.jsx)(e.pre,{children:(0,s.jsx)(e.code,{className:"language-bash",children:'# Monitor GPU usage\nnvidia-smi\n\n# Watch GPU usage in real-time\nwatch -n 1 nvidia-smi\n\n# Check CUDA availability in Python\npython -c "import torch; print(torch.cuda.is_available())"\n'})}),"\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"Get Help:"})}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsxs)(e.li,{children:["PyTorch Forums: ",(0,s.jsx)(e.a,{href:"https://discuss.pytorch.org/",children:"https://discuss.pytorch.org/"})]}),"\n",(0,s.jsxs)(e.li,{children:["GitHub Issues: ",(0,s.jsx)(e.a,{href:"https://github.com/pytorch/pytorch/issues",children:"https://github.com/pytorch/pytorch/issues"})]}),"\n",(0,s.jsxs)(e.li,{children:["Stack Overflow: Tag ",(0,s.jsx)(e.code,{children:"pytorch"})]}),"\n",(0,s.jsxs)(e.li,{children:["Documentation: ",(0,s.jsx)(e.a,{href:"https://pytorch.org/docs/",children:"https://pytorch.org/docs/"})]}),"\n"]}),"\n",(0,s.jsx)(e.h3,{id:"environment-validation-script",children:"Environment Validation Script"}),"\n",(0,s.jsxs)(e.p,{children:["Create ",(0,s.jsx)(e.code,{children:"validate_pytorch_setup.py"})," to test all components:"]}),"\n",(0,s.jsx)(e.pre,{children:(0,s.jsx)(e.code,{className:"language-python",children:'#!/usr/bin/env python3\n"""\nComplete PyTorch Setup Validation Script\nTests all major components and reports issues\n"""\nimport sys\nimport time\n\ndef validate_complete_setup():\n    """Comprehensive validation of PyTorch setup"""\n    print("=" * 70)\n    print("PyTorch Complete Setup Validation")\n    print("=" * 70)\n\n    issues = []\n\n    # 1. Test PyTorch import and version\n    print("\\n[1/8] Testing PyTorch Installation...")\n    try:\n        import torch\n        print(f"  \u2713 PyTorch {torch.__version__}")\n    except ImportError as e:\n        print(f"  \u2717 Failed: {e}")\n        issues.append("PyTorch not installed")\n        return issues\n\n    # 2. Test CUDA\n    print("\\n[2/8] Testing CUDA Support...")\n    if torch.cuda.is_available():\n        print(f"  \u2713 CUDA {torch.version.cuda}")\n        print(f"  \u2713 {torch.cuda.device_count()} GPU(s) available")\n        for i in range(torch.cuda.device_count()):\n            print(f"    - {torch.cuda.get_device_name(i)}")\n    else:\n        print("  ! CUDA not available (CPU-only mode)")\n        issues.append("CUDA not available")\n\n    # 3. Test tensor operations\n    print("\\n[3/8] Testing Tensor Operations...")\n    try:\n        x = torch.randn(100, 100)\n        y = torch.randn(100, 100)\n        z = torch.matmul(x, y)\n        assert z.shape == (100, 100)\n        print("  \u2713 Basic tensor operations work")\n    except Exception as e:\n        print(f"  \u2717 Failed: {e}")\n        issues.append("Tensor operations failed")\n\n    # 4. Test GPU transfer\n    print("\\n[4/8] Testing GPU Transfer...")\n    if torch.cuda.is_available():\n        try:\n            x_gpu = x.cuda()\n            y_gpu = y.cuda()\n            z_gpu = torch.matmul(x_gpu, y_gpu)\n            print("  \u2713 GPU transfer and computation work")\n        except Exception as e:\n            print(f"  \u2717 Failed: {e}")\n            issues.append("GPU transfer failed")\n    else:\n        print("  - Skipped (no CUDA)")\n\n    # 5. Test neural network\n    print("\\n[5/8] Testing Neural Network...")\n    try:\n        import torch.nn as nn\n        model = nn.Sequential(\n            nn.Linear(10, 20),\n            nn.ReLU(),\n            nn.Linear(20, 5)\n        )\n        input_data = torch.randn(32, 10)\n        output = model(input_data)\n        assert output.shape == (32, 5)\n        print("  \u2713 Neural network creation and forward pass work")\n    except Exception as e:\n        print(f"  \u2717 Failed: {e}")\n        issues.append("Neural network failed")\n\n    # 6. Test backpropagation\n    print("\\n[6/8] Testing Backpropagation...")\n    try:\n        import torch.optim as optim\n        criterion = nn.MSELoss()\n        optimizer = optim.SGD(model.parameters(), lr=0.01)\n\n        target = torch.randn(32, 5)\n        optimizer.zero_grad()\n        loss = criterion(output, target)\n        loss.backward()\n        optimizer.step()\n        print("  \u2713 Backpropagation and optimization work")\n    except Exception as e:\n        print(f"  \u2717 Failed: {e}")\n        issues.append("Backpropagation failed")\n\n    # 7. Test DataLoader\n    print("\\n[7/8] Testing DataLoader...")\n    try:\n        from torch.utils.data import TensorDataset, DataLoader\n        dataset = TensorDataset(torch.randn(100, 10), torch.randn(100, 5))\n        loader = DataLoader(dataset, batch_size=16, shuffle=True)\n        batch = next(iter(loader))\n        print("  \u2713 DataLoader works")\n    except Exception as e:\n        print(f"  \u2717 Failed: {e}")\n        issues.append("DataLoader failed")\n\n    # 8. Test torchvision\n    print("\\n[8/8] Testing Torchvision...")\n    try:\n        import torchvision\n        from torchvision import transforms\n        transform = transforms.Compose([\n            transforms.ToTensor(),\n            transforms.Normalize((0.5,), (0.5,))\n        ])\n        print(f"  \u2713 Torchvision {torchvision.__version__}")\n    except ImportError:\n        print("  ! Torchvision not installed (optional)")\n        issues.append("Torchvision not installed")\n\n    # Summary\n    print("\\n" + "=" * 70)\n    if not issues:\n        print("\u2713 All tests passed! PyTorch setup is complete.")\n    else:\n        print(f"\u2717 Found {len(issues)} issue(s):")\n        for issue in issues:\n            print(f"  - {issue}")\n    print("=" * 70)\n\n    return issues\n\nif __name__ == "__main__":\n    issues = validate_complete_setup()\n    sys.exit(len(issues))\n'})}),"\n",(0,s.jsx)(e.p,{children:"Run the validation:"}),"\n",(0,s.jsx)(e.pre,{children:(0,s.jsx)(e.code,{className:"language-bash",children:"python validate_pytorch_setup.py\n"})}),"\n",(0,s.jsx)(e.p,{children:"This script tests all critical components and helps identify any setup issues."}),"\n",(0,s.jsx)(e.h2,{id:"conclusion",children:"Conclusion"}),"\n",(0,s.jsx)(e.p,{children:"This comprehensive PyTorch tutorial covers the essential aspects of machine learning and deep learning implementation, from basic tensor operations to production deployment. Key takeaways include:"}),"\n",(0,s.jsx)(e.h3,{id:"core-concepts-covered",children:"Core Concepts Covered"}),"\n",(0,s.jsxs)(e.ol,{children:["\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"PyTorch Fundamentals"}),": Tensors, autograd, and basic operations"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Data Handling"}),": Custom datasets, data loaders, and preprocessing"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Neural Networks"}),": From simple MLPs to advanced architectures"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Training"}),": Optimization, loss functions, and training loops"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Computer Vision"}),": CNNs, transfer learning, and specialized architectures"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"NLP"}),": RNNs, Transformers, and text processing"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Advanced Topics"}),": Custom losses, regularization, and interpretability"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Production"}),": Model optimization, quantization, and deployment"]}),"\n"]}),"\n",(0,s.jsx)(e.h3,{id:"best-practices",children:"Best Practices"}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsx)(e.li,{children:"Use appropriate data augmentation and preprocessing"}),"\n",(0,s.jsx)(e.li,{children:"Implement proper validation and early stopping"}),"\n",(0,s.jsx)(e.li,{children:"Monitor training with comprehensive metrics"}),"\n",(0,s.jsx)(e.li,{children:"Apply regularization techniques to prevent overfitting"}),"\n",(0,s.jsx)(e.li,{children:"Optimize models for production deployment"}),"\n",(0,s.jsx)(e.li,{children:"Use mixed precision training for efficiency"}),"\n",(0,s.jsx)(e.li,{children:"Implement proper error handling and logging"}),"\n"]}),"\n",(0,s.jsx)(e.h3,{id:"next-steps-1",children:"Next Steps"}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsx)(e.li,{children:"Explore domain-specific applications"}),"\n",(0,s.jsx)(e.li,{children:"Implement state-of-the-art architectures"}),"\n",(0,s.jsx)(e.li,{children:"Experiment with distributed training"}),"\n",(0,s.jsx)(e.li,{children:"Learn about model compression techniques"}),"\n",(0,s.jsx)(e.li,{children:"Practice with real-world datasets"}),"\n",(0,s.jsx)(e.li,{children:"Contribute to open-source projects"}),"\n"]}),"\n",(0,s.jsx)(e.p,{children:"This tutorial provides a solid foundation for building and deploying machine learning models with PyTorch. Continue practicing with different datasets and architectures to master these concepts."}),"\n",(0,s.jsx)(e.hr,{}),"\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.em,{children:"Last updated: September 2023"})})]})}function p(n={}){const{wrapper:e}={...(0,i.R)(),...n.components};return e?(0,s.jsx)(e,{...n,children:(0,s.jsx)(c,{...n})}):c(n)}}}]);