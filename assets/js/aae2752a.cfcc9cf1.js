"use strict";(self.webpackChunkliangchao_website=self.webpackChunkliangchao_website||[]).push([[2499],{823:e=>{e.exports=JSON.parse('{"permalink":"/blog/curriculum-vitae","editUrl":"https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/blog/2100-01-01-curriculum-vitae.md","source":"@site/blog/2100-01-01-curriculum-vitae.md","title":"Curriculum Vitae","description":"Personal Information","date":"2100-01-01T00:00:00.000Z","tags":[{"inline":false,"label":"Curriculum Vitae","permalink":"/blog/tags/curriculum vitae","description":"Curriculum Vitae tag description"},{"inline":false,"label":"Academic CV","permalink":"/blog/tags/academic-cv","description":"Academic curriculum vitae"}],"readingTime":4.89,"hasTruncateMarker":true,"authors":[{"name":"Liangchao Deng","title":"PhD @ SHZU","url":"https://github.com/smiler488","page":{"permalink":"/blog/authors/liangchao"},"socials":{"x":"https://x.com/smiler488","github":"https://github.com/smiler488"},"imageURL":"https://github.com/smiler488.png","key":"liangchao"}],"frontMatter":{"slug":"curriculum-vitae","title":"Curriculum Vitae","authors":["liangchao"],"tags":["curriculum vitae","academic cv"]},"unlisted":false,"nextItem":{"title":"A complete guide for graduate students and early-career researchers on how to prepare, submit, and publish scientific papers","permalink":"/blog/academic-paper-publication-guide"}}')},2161:(e,n,i)=>{i.r(n),i.d(n,{assets:()=>a,contentTitle:()=>c,default:()=>g,frontMatter:()=>l,metadata:()=>r,toc:()=>h});var r=i(823),t=i(4848),s=i(8453),o=i(8468);const l={slug:"curriculum-vitae",title:"Curriculum Vitae",authors:["liangchao"],tags:["curriculum vitae","academic cv"]},c="Curriculum Vitae",a={authorsImageUrls:[void 0]},h=[{value:"Personal Information",id:"personal-information",level:2},{value:"Education",id:"education",level:2},{value:"Research Interests",id:"research-interests",level:2},{value:"Cutting-Edge Technology Focus",id:"cutting-edge-technology-focus",level:3},{value:"Core Research Domains",id:"core-research-domains",level:3},{value:"Innovation and Impact",id:"innovation-and-impact",level:3},{value:"Research Experience",id:"research-experience",level:2},{value:"<strong>Generative AI for Agricultural Applications</strong> | <em>2024 \u2013 Present</em>",id:"generative-ai-for-agricultural-applications--2024--present",level:3},{value:"<strong>Next-Generation Phenotyping with Advanced Computer Vision</strong> | <em>2021 \u2013 Present</em>",id:"next-generation-phenotyping-with-advanced-computer-vision--2021--present",level:3},{value:"Technical Expertise",id:"technical-expertise",level:2},{value:"<strong>Artificial Intelligence &amp; Machine Learning</strong>",id:"artificial-intelligence--machine-learning",level:3},{value:"<strong>Advanced Computer Vision &amp; Graphics</strong>",id:"advanced-computer-vision--graphics",level:3},{value:"<strong>High-Performance Computing &amp; Cloud</strong>",id:"high-performance-computing--cloud",level:3},{value:"<strong>Agricultural Technology</strong>",id:"agricultural-technology",level:3},{value:"<strong>Research &amp; Development Tools</strong>",id:"research--development-tools",level:3},{value:"Publications &amp; Research Output",id:"publications--research-output",level:2},{value:"<strong>Accepted / In Press</strong>",id:"accepted--in-press",level:3},{value:"Teaching and Mentoring Experience",id:"teaching-and-mentoring-experience",level:2},{value:"<strong>Student Mentoring</strong>",id:"student-mentoring",level:3},{value:"Innovation &amp; Entrepreneurship",id:"innovation--entrepreneurship",level:2},{value:"<strong>Open-Source Contributions</strong>",id:"open-source-contributions",level:3},{value:"Languages",id:"languages",level:2},{value:"References",id:"references",level:2}];function d(e){const n={a:"a",em:"em",h2:"h2",h3:"h3",hr:"hr",li:"li",ol:"ol",p:"p",strong:"strong",ul:"ul",...(0,s.R)(),...e.components};return(0,t.jsxs)(t.Fragment,{children:[(0,t.jsx)(n.h2,{id:"personal-information",children:"Personal Information"}),"\n",(0,t.jsxs)("p",{className:"cvPronunciation",children:[(0,t.jsx)("span",{className:"cvNameText",children:(0,t.jsxs)(n.p,{children:[(0,t.jsx)("strong",{children:"Liangchao Deng"})," (\u9093\u826f\u8d85)"]})}),(0,t.jsx)(o.A,{text:"\u9093\u826f\u8d85",fallbackText:"Pronunciation: Li\xe1ng-ch\u0101o (lee-ANG chao)",title:"Play pronunciation"})]}),"\n",(0,t.jsx)(n.p,{children:"Ph.D. Candidate in Crop Science, College of Agriculture, Shihezi University, Shihezi, Xinjiang 832003, China"}),"\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.strong,{children:"Contact Information:"})}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Institutional Email:"})," ",(0,t.jsx)(n.a,{href:"mailto:liangchaodeng@stu.shzu.edu.cn",children:"liangchaodeng@stu.shzu.edu.cn"})]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Personal Email:"})," ",(0,t.jsx)(n.a,{href:"mailto:googalphdlc@gmail.com",children:"googalphdlc@gmail.com"})]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Website:"})," ",(0,t.jsx)(n.a,{href:"https://smiler488.github.io",children:"https://smiler488.github.io"})]}),"\n"]}),"\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.strong,{children:"Academic Profiles:"})}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"ORCID:"})," ",(0,t.jsx)(n.a,{href:"https://orcid.org/0000-0002-5194-0655",children:"0000-0002-5194-0655"})]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Google Scholar:"})," ",(0,t.jsx)(n.a,{href:"https://scholar.google.com/citations?hl=en&user=u3GFRMQAAAAJ&view_op=list_works",children:"Profile"})]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"ResearchGate:"})," ",(0,t.jsx)(n.a,{href:"https://www.researchgate.net/profile/Liangchao-Deng?ev=hdr_xprf",children:"Profile"})]}),"\n"]}),"\n",(0,t.jsx)(n.hr,{}),"\n",(0,t.jsx)(n.h2,{id:"education",children:"Education"}),"\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.strong,{children:"Ph.D. in Crop Science"})," | ",(0,t.jsx)(n.em,{children:"2023 \u2013 2026 (expected)"})," \xb7 Shihezi University, Xinjiang, China"]}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Supervisors:"})," Prof. Yali Zhang (SHZU) & Dr. Qingfeng Song (CAS-CEMPS)"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Dissertation Topic:"})," AI-Enhanced High-Throughput Phenotyping and 3D Canopy Modeling for Smart Agriculture"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"B.Sc. in Information and Computational Science"})," | ",(0,t.jsx)(n.em,{children:"2016 \u2013 2021"})," \xb7 Shihezi University, Xinjiang, China"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Thesis:"})," Research on the optimization of cotton canopy structure and photosynthetic efficiency improvement based on multi-scale three-dimensional reconstruction and ray tracing"]}),"\n"]}),"\n",(0,t.jsx)(n.hr,{}),"\n",(0,t.jsx)(n.h2,{id:"research-interests",children:"Research Interests"}),"\n",(0,t.jsx)(n.h3,{id:"cutting-edge-technology-focus",children:"Cutting-Edge Technology Focus"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Generative AI for Agriculture:"})," Image-to-3D plant modeling; foundation models for crop phenotyping; multimodal systems"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Advanced Computer Vision:"})," SFM, NeRF, 3D Gaussian Splatting, differentiable rendering for plant/canopy reconstruction based on cameras/UAV"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"AI-Assisted Scientific Computing:"})," LLM integration in research workflows; AI-assisted code generation for phenotyping pipelines"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Digital Agriculture Innovation:"})," IoT sensor; real-time monitoring"]}),"\n"]}),"\n",(0,t.jsx)(n.h3,{id:"core-research-domains",children:"Core Research Domains"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Precision Phenomics:"})," High-throughput phenotyping using UAVs, hyperspectral/multispectral imaging, and LiDAR point clouds"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Computational Plant Biology:"})," Ray-tracing photosynthesis models; BRDF-based optical simulations"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Environment-Smart Agriculture:"})," AI-driven crop adaptation strategies; predictive modeling for environmental resilience"]}),"\n"]}),"\n",(0,t.jsx)(n.h3,{id:"innovation-and-impact",children:"Innovation and Impact"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"Bridging newest technology with practical agricultural solutions"}),"\n",(0,t.jsx)(n.li,{children:"Developing scalable technologies for global food security"}),"\n",(0,t.jsx)(n.li,{children:"Creating open-source tools for the international ag-research community"}),"\n"]}),"\n",(0,t.jsx)(n.hr,{}),"\n",(0,t.jsx)(n.h2,{id:"research-experience",children:"Research Experience"}),"\n",(0,t.jsxs)(n.h3,{id:"generative-ai-for-agricultural-applications--2024--present",children:[(0,t.jsx)(n.strong,{children:"Generative AI for Agricultural Applications"})," | ",(0,t.jsx)(n.em,{children:"2024 \u2013 Present"})]}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Innovation:"})," Built image-to-3D generative workflows (diffusion, NeRF) for rapid plant architecture synthesis, Establish a general crop crown photosynthetic prediction model based on multi-modal phenotype data"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"AI Integration:"})," Fine-tuned LLMs for domain-specific analysis and automated research pipelines"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Technical Achievement:"})," AI-assisted coding framework accelerating phenotyping algorithm development"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Impact:"})," Reduced 3D plant model generation from days to minutes, enabling near-real-time digital twins"]}),"\n"]}),"\n",(0,t.jsxs)(n.h3,{id:"next-generation-phenotyping-with-advanced-computer-vision--2021--present",children:[(0,t.jsx)(n.strong,{children:"Next-Generation Phenotyping with Advanced Computer Vision"})," | ",(0,t.jsx)(n.em,{children:"2021 \u2013 Present"})]}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"Implemented 3D Gaussian Splatting and differentiable rendering for photorealistic plant/canopy reconstruction"}),"\n",(0,t.jsx)(n.li,{children:"Deployed multi-view stereo (SfM/MVS) and LiDAR for high-fidelity structure capture and trait extraction"}),"\n",(0,t.jsx)(n.li,{children:"Based on the three-dimensional point cloud model and ray tracing algorithm of plants, build a cotton canopy photosythetic model and simulate the space-time distribution of canopy light and photosynthesis."}),"\n",(0,t.jsx)(n.li,{children:"Explored the optimal combination of plant architecture and agronomic practices with maximum photosynthetic rate as the objective"}),"\n",(0,t.jsx)(n.li,{children:"According to the working principle of real lidar, use ray tracing algorithms to build virtual lidar, simulate radar scanning plant canopy, and obtain a large number of synthetic data training models, accelerate the development of the phenotype platform"}),"\n"]}),"\n",(0,t.jsx)(n.hr,{}),"\n",(0,t.jsx)(n.h2,{id:"technical-expertise",children:"Technical Expertise"}),"\n",(0,t.jsx)(n.h3,{id:"artificial-intelligence--machine-learning",children:(0,t.jsx)(n.strong,{children:"Artificial Intelligence & Machine Learning"})}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Deep Learning:"})," PyTorch, TensorFlow, Transformers, CUDA"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Generative AI:"})," Diffusion models, NeRF, 3DGS, text-/image-to-3D"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Foundation Models:"})," LLM fine-tuning, CLIP, prompt engineering"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"MLOps:"})," Docker, distributed training on multi-GPU"]}),"\n"]}),"\n",(0,t.jsx)(n.h3,{id:"advanced-computer-vision--graphics",children:(0,t.jsx)(n.strong,{children:"Advanced Computer Vision & Graphics"})}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"3D Reconstruction:"})," SfM/MVS, 3DGS, photogrammetry, point-cloud processing"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Rendering:"})," Ray tracing"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Real-time Processing:"})," OpenCV, CUDA/TensorRT; edge deployment (NVIDIA Jetson)"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Libraries/Tools:"})," Open3D, PCL, Blender Python API, Three.js (web viz)"]}),"\n"]}),"\n",(0,t.jsx)(n.h3,{id:"high-performance-computing--cloud",children:(0,t.jsx)(n.strong,{children:"High-Performance Computing & Cloud"})}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Programming:"})," Python, MATLAB, R"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"DevOps:"})," Git, containerization; parallel data processing on HPC"]}),"\n"]}),"\n",(0,t.jsx)(n.h3,{id:"agricultural-technology",children:(0,t.jsx)(n.strong,{children:"Agricultural Technology"})}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Remote Sensing:"})," RGB / multispectral / hyperspectral / thermal; LiDAR; UAV systems"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Sensor Networks:"})," IoT devices for microclimate & photosynthesis monitoring"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Data Standards:"})," GeoTIFF and common ag-data exchange formats"]}),"\n"]}),"\n",(0,t.jsx)(n.h3,{id:"research--development-tools",children:(0,t.jsx)(n.strong,{children:"Research & Development Tools"})}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Scientific Computing:"})," Python, MATLAB, R; numerical modeling"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Collaboration:"})," GitHub, Slack, Notion; academic writing (Markdown, Overleaf)"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Project Management:"})," Agile/Scrum; reproducible research workflows"]}),"\n"]}),"\n",(0,t.jsx)(n.hr,{}),"\n",(0,t.jsx)(n.h2,{id:"publications--research-output",children:"Publications & Research Output"}),"\n",(0,t.jsx)(n.h3,{id:"accepted--in-press",children:(0,t.jsx)(n.strong,{children:"Accepted / In Press"})}),"\n",(0,t.jsxs)(n.ol,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Deng, L."}),", Yu, L. X., Mao, L., Wang, Y., Guo, X., Wang, M., Zhang, Y., Song, Q., Zhu, X.-G. (2025).\n",(0,t.jsx)(n.em,{children:"Leaf Optical Properties Predicted with BRDF and Phenotypic Traits in Four Species: Development of Novel Analysis Tools."})," ",(0,t.jsx)(n.strong,{children:"Plant Phenomics"})," ",(0,t.jsx)(n.a,{href:"https://doi.org/10.1016/j.plaphe.2025.100135",children:"DOI:10.1016/j.plaphe.2025.100135"})," ",(0,t.jsx)(n.a,{target:"_blank","data-noBrokenLinkCheck":!0,href:i(4488).A+"",children:(0,t.jsx)(n.strong,{children:"PDF"})})]}),"\n"]}),"\n",(0,t.jsx)(n.hr,{}),"\n",(0,t.jsx)(n.h2,{id:"teaching-and-mentoring-experience",children:"Teaching and Mentoring Experience"}),"\n",(0,t.jsx)(n.h3,{id:"student-mentoring",children:(0,t.jsx)(n.strong,{children:"Student Mentoring"})}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Yu Jingxuan"})," | ",(0,t.jsx)(n.em,{children:"Undergraduate Research"})," | ",(0,t.jsx)(n.em,{children:"2023 \u2013 2025"}),(0,t.jsx)(n.strong,{children:"Project:"})," Field-scale 3D reconstruction & quantitative analysis of cotton varieties (UAV)",(0,t.jsx)(n.strong,{children:"Role/Outcome:"})," Guided MVS pipeline; student gained 3D modeling & data-analysis proficiency"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Zhang Rongze"})," | ",(0,t.jsx)(n.em,{children:"Undergraduate Research"})," | ",(0,t.jsx)(n.em,{children:"2023 \u2013 2025"}),(0,t.jsx)(n.strong,{children:"Project:"})," Single-plant 3D reconstruction & morphological quantification",(0,t.jsx)(n.strong,{children:"Role/Outcome:"})," Contributed to automated phenotyping workflow"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Xie Hejiang"})," | ",(0,t.jsx)(n.em,{children:"Undergraduate Research"})," | ",(0,t.jsx)(n.em,{children:"2023 \u2013 2025"}),"\n",(0,t.jsx)(n.strong,{children:"Project:"})," Cotton yield response under nitrogen treatment regimes\n",(0,t.jsx)(n.strong,{children:"Role/Outcome:"})," Trained in experimental design & statistics; results supported N optimization"]}),"\n"]}),"\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.strong,{children:"Mentoring Philosophy:"})," Hands-on learning; rigorous experimental design; integration of computation with agronomy; reproducible, open science."]}),"\n",(0,t.jsx)(n.hr,{}),"\n",(0,t.jsx)(n.h2,{id:"innovation--entrepreneurship",children:"Innovation & Entrepreneurship"}),"\n",(0,t.jsx)(n.h3,{id:"open-source-contributions",children:(0,t.jsx)(n.strong,{children:"Open-Source Contributions"})}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Stereo-Vision-Camera-Box"})," \xb7 ",(0,t.jsx)(n.em,{children:"Python, Computer Vision"}),"Advanced stereo-vision system with custom hardware & GUI for depth and 3D point clouds in phenotyping.",(0,t.jsx)(n.a,{href:"https://github.com/smiler488/Stereo-Vision-Camera-Box",children:"https://github.com/smiler488/Stereo-Vision-Camera-Box"})]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"CCO-Flight-Planner"})," \xb7 ",(0,t.jsx)(n.em,{children:"Python, UAV Technology"}),"Automated DJI flight planning from KML polygons; KMZ waypoint generation for field surveys.",(0,t.jsx)(n.a,{href:"https://github.com/smiler488/cco-flight-planner",children:"https://github.com/smiler488/cco-flight-planner"})]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"RootQuantify"})," \xb7 ",(0,t.jsx)(n.em,{children:"Python, Image Analysis"}),"Batch root-image quantification with robust preprocessing and morphology metrics.",(0,t.jsx)(n.a,{href:"https://github.com/smiler488/RootQuantify",children:"https://github.com/smiler488/RootQuantify"})]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Custom-Harvard-Citation-Tool"})," \xb7 ",(0,t.jsx)(n.em,{children:"Academic Productivity"}),"\nZotero-friendly citation insertion with journal-abbreviation support (slides/papers).\n",(0,t.jsx)(n.a,{href:"https://github.com/smiler488/custom-harvard-with-journal-abbr",children:"https://github.com/smiler488/custom-harvard-with-journal-abbr"})]}),"\n"]}),"\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.strong,{children:"Technical Impact:"})," 50+ combined stars; adopted in practical ag-research workflows."]}),"\n",(0,t.jsx)(n.hr,{}),"\n",(0,t.jsx)(n.h2,{id:"languages",children:"Languages"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Chinese (Mandarin):"})," Native"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"English:"})," Proficient (academic writing, presentations, collaboration)"]}),"\n"]}),"\n",(0,t.jsx)(n.hr,{}),"\n",(0,t.jsx)(n.h2,{id:"references",children:"References"}),"\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.strong,{children:"Prof. Yali Zhang"}),"\nProfessor & Ph.D. Supervisor, College of Agriculture, Shihezi University\nEmail: ",(0,t.jsx)(n.a,{href:"mailto:zhangyali_cn@foxmail.com",children:"zhangyali_cn@foxmail.com"})]}),"\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.strong,{children:"Dr. Qingfeng Song"}),"\nResearch Associate & Co-supervisor, CAS Center for Excellence in Molecular Plant Sciences (CEMPS)\nEmail: ",(0,t.jsx)(n.a,{href:"mailto:zhangyali_cn@foxmail.com",children:"songqf@cemps.ac.cn"})]}),"\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.strong,{children:"Additional references available upon request"})}),"\n",(0,t.jsx)(n.hr,{}),"\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.em,{children:"Last updated: October 2025"})})]})}function g(e={}){const{wrapper:n}={...(0,s.R)(),...e.components};return n?(0,t.jsx)(n,{...e,children:(0,t.jsx)(d,{...e})}):d(e)}},4488:(e,n,i)=>{i.d(n,{A:()=>r});const r=i.p+"assets/files/brdf-c383ce9db0903263a9a368551045ce37.pdf"},8453:(e,n,i)=>{i.d(n,{R:()=>o,x:()=>l});var r=i(6540);const t={},s=r.createContext(t);function o(e){const n=r.useContext(s);return r.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function l(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(t):e.components||t:o(e.components),r.createElement(s.Provider,{value:n},e.children)}},8468:(e,n,i)=>{i.d(n,{A:()=>l});var r=i(6540);const t="speechButton_B_OT",s="tooltip_zcQP";var o=i(4848);const l=({text:e,fallbackText:n,lang:i="zh-CN",rate:l=.8,pitch:c=1,className:a="",title:h="Click to hear pronunciation"})=>{const[d,g]=(0,r.useState)(!1),[u,p]=(0,r.useState)(!1),[m,x]=(0,r.useState)(!1),[j,f]=(0,r.useState)([]);(0,r.useEffect)((()=>{if("undefined"!=typeof window&&"speechSynthesis"in window){g(!0);const e=()=>{const e=speechSynthesis.getVoices();f(e),p(e.length>0)};return e(),speechSynthesis.addEventListener("voiceschanged",e),()=>{speechSynthesis.removeEventListener("voiceschanged",e)}}}),[]);const v=e=>{const n=document.createElement("div");n.textContent=e,n.className=s,document.body.appendChild(n);const i=document.activeElement?.getBoundingClientRect();i&&(n.style.left=`${i.left+i.width/2}px`,n.style.top=i.top-40+"px"),setTimeout((()=>{n.parentNode&&n.parentNode.removeChild(n)}),2e3)};return(0,o.jsx)("button",{onClick:async()=>{if(d&&e)if(u)try{speechSynthesis.cancel();const r=new SpeechSynthesisUtterance(e),t=(e=>{if(!j.length)return null;let n=j.find((n=>n.lang===e));if(n)return n;const i=e.split("-")[0];return n=j.find((e=>e.lang.startsWith(i))),n||j.find((e=>e.default))||j[0]})(i);t&&(r.voice=t),r.lang=i,r.rate=l,r.pitch=c,r.volume=1,r.onstart=()=>x(!0),r.onend=()=>x(!1),r.onerror=i=>{console.error("Speech synthesis error:",i.error),x(!1);v(n||`Pronunciation: ${e}`)},speechSynthesis.speak(r)}catch(r){console.error("Speech error:",r),x(!1);v(n||`Pronunciation: ${e}`)}else v("Speech synthesis not ready yet");else{v(n||`Pronunciation: ${e}`)}},className:`${t} ${a}`,title:h,disabled:m,"aria-label":`Pronounce ${e}`,children:m?"\ud83d\udd07":"\ud83d\udd0a"})}}}]);