"use strict";(self.webpackChunkliangchao_website=self.webpackChunkliangchao_website||[]).push([[5793],{13342:(n,i,e)=>{e.r(i),e.d(i,{assets:()=>l,contentTitle:()=>a,default:()=>h,frontMatter:()=>r,metadata:()=>o,toc:()=>c});var o=e(46682),t=e(74848),s=e(28453);const r={slug:"uav-3d-crop-phenotyping",title:"UAV 3D Crop Phenotyping: From Image Acquisition to Machine Learning Modeling",authors:["liangchao"],tags:["UAV","3D Reconstruction","Phenomics","Machine Learning","Agriculture"],description:"Comprehensive guide to UAV-based 3D crop phenotyping workflow, including CCO flight path design, orthophoto mosaic, SfM and 3DGS 3D reconstruction, and 3D structural phenotyping with machine learning analysis."},a=void 0,l={authorsImageUrls:[void 0]},c=[{value:"1. Flight Path Design and Image Acquisition",id:"1-flight-path-design-and-image-acquisition",level:2},{value:"Key Design Points:",id:"key-design-points",level:3},{value:"2. Orthophoto Mosaic and Spatial Reference Construction",id:"2-orthophoto-mosaic-and-spatial-reference-construction",level:2},{value:"Main Purposes:",id:"main-purposes",level:3},{value:"3. Field Boundary Extraction Based on Orthophotos",id:"3-field-boundary-extraction-based-on-orthophotos",level:2},{value:"Extraction Steps:",id:"extraction-steps",level:3},{value:"4. Farmland Crop 3D Reconstruction",id:"4-farmland-crop-3d-reconstruction",level:2},{value:"4.1 SfM Point Cloud Reconstruction",id:"41-sfm-point-cloud-reconstruction",level:3},{value:"Application Scenarios:",id:"application-scenarios",level:4},{value:"4.2 3D Gaussian Splatting (3DGS)",id:"42-3d-gaussian-splatting-3dgs",level:3},{value:"Technical Advantages:",id:"technical-advantages",level:4},{value:"5. 3D Crop Phenotyping Quantification and Machine Learning Analysis",id:"5-3d-crop-phenotyping-quantification-and-machine-learning-analysis",level:2},{value:"5.1 3D Structural Phenotypic Feature Construction",id:"51-3d-structural-phenotypic-feature-construction",level:3},{value:"Phenotypic Features:",id:"phenotypic-features",level:4},{value:"5.2 Machine Learning Modeling",id:"52-machine-learning-modeling",level:3},{value:"Analysis Workflow:",id:"analysis-workflow",level:4},{value:"6. CanopyPC: Plant Canopy Point Cloud Processing Tool",id:"6-canopypc-plant-canopy-point-cloud-processing-tool",level:2},{value:"Features",id:"features",level:3},{value:"Ground-Canopy Segmentation",id:"ground-canopy-segmentation",level:4},{value:"Point Cloud Preprocessing",id:"point-cloud-preprocessing",level:4},{value:"Canopy Row Segmentation",id:"canopy-row-segmentation",level:4},{value:"Geometric Analysis",id:"geometric-analysis",level:4},{value:"Visualization",id:"visualization",level:4},{value:"Summary",id:"summary",level:2}];function d(n){const i={em:"em",h2:"h2",h3:"h3",h4:"h4",hr:"hr",img:"img",li:"li",ol:"ol",p:"p",strong:"strong",ul:"ul",...(0,s.R)(),...n.components};return(0,t.jsxs)(t.Fragment,{children:[(0,t.jsx)(i.h2,{id:"1-flight-path-design-and-image-acquisition",children:"1. Flight Path Design and Image Acquisition"}),"\n",(0,t.jsxs)(i.p,{children:["UAV image acquisition employs a ",(0,t.jsx)(i.strong,{children:"CCO (Cross-Complementary Overlap) flight path design strategy"}),". This strategy enhances viewpoint diversity through multi-directional cross-flight paths to strengthen geometric constraints for 3D reconstruction.\n",(0,t.jsx)(i.img,{alt:"Flight Path Design Diagram",src:e(57386).A+"",width:"416",height:"244"})]}),"\n",(0,t.jsx)(i.h3,{id:"key-design-points",children:"Key Design Points:"}),"\n",(0,t.jsxs)(i.ul,{children:["\n",(0,t.jsxs)(i.li,{children:[(0,t.jsx)(i.strong,{children:"Multi sets of flight paths in different directions"}),": Ensures multi-angle capture of crop canopy structure"]}),"\n",(0,t.jsxs)(i.li,{children:[(0,t.jsx)(i.strong,{children:"Forward and side overlap rates higher than conventional orthophoto requirements"}),": Provides sufficient matching points for SfM reconstruction"]}),"\n",(0,t.jsxs)(i.li,{children:[(0,t.jsx)(i.strong,{children:"Image acquisition primarily serves 3D reconstruction goals"}),": Rather than only satisfying orthophoto mosaic requirements"]}),"\n"]}),"\n",(0,t.jsx)(i.p,{children:"Based on industry-grade UAV platforms, multi-view RGB images of farmland are collected to provide unified data sources for subsequent orthophoto mosaic and 3D modeling."}),"\n",(0,t.jsx)(i.h2,{id:"2-orthophoto-mosaic-and-spatial-reference-construction",children:"2. Orthophoto Mosaic and Spatial Reference Construction"}),"\n",(0,t.jsx)(i.p,{children:"Multi-view images are first orthorectified and mosaicked to generate high-resolution orthophotos. Orthophotos in this workflow are primarily used for:"}),"\n",(0,t.jsx)(i.h3,{id:"main-purposes",children:"Main Purposes:"}),"\n",(0,t.jsxs)(i.ul,{children:["\n",(0,t.jsxs)(i.li,{children:[(0,t.jsx)(i.strong,{children:"Constructing unified 2D spatial reference"}),": Providing baseline coordinate system for subsequent analysis"]}),"\n",(0,t.jsxs)(i.li,{children:[(0,t.jsx)(i.strong,{children:"Supporting precise field boundary extraction"}),": Field boundary identification based on orthophotos"]}),"\n",(0,t.jsxs)(i.li,{children:[(0,t.jsx)(i.strong,{children:"Providing projection alignment foundation for 3D results"}),": Ensuring spatial consistency between 3D reconstruction results and 2D baseline"]}),"\n"]}),"\n",(0,t.jsx)(i.p,{children:"Orthophotos serve as 2D baseline and are not directly used for phenotypic analysis."}),"\n",(0,t.jsx)(i.h2,{id:"3-field-boundary-extraction-based-on-orthophotos",children:"3. Field Boundary Extraction Based on Orthophotos"}),"\n",(0,t.jsx)(i.p,{children:"Field boundaries are extracted through image-driven processing using orthophotos, with the following workflow:"}),"\n",(0,t.jsx)(i.h3,{id:"extraction-steps",children:"Extraction Steps:"}),"\n",(0,t.jsxs)(i.ol,{children:["\n",(0,t.jsxs)(i.li,{children:[(0,t.jsx)(i.strong,{children:"Distinguish crop-covered areas from non-crop regions"}),": Utilize vegetation indices and texture features"]}),"\n",(0,t.jsxs)(i.li,{children:[(0,t.jsx)(i.strong,{children:"Remove roads, bare land, and boundary interference"}),": Apply morphological operations and region growing algorithms"]}),"\n",(0,t.jsxs)(i.li,{children:[(0,t.jsx)(i.strong,{children:"Generate closed polygons as actual field boundaries"}),": Based on contour extraction and polygon fitting"]}),"\n"]}),"\n",(0,t.jsx)(i.p,{children:"Extracted field boundaries serve as spatial constraints for subsequent 3D reconstruction and phenotypic calculations."}),"\n",(0,t.jsx)(i.h2,{id:"4-farmland-crop-3d-reconstruction",children:"4. Farmland Crop 3D Reconstruction"}),"\n",(0,t.jsx)(i.h3,{id:"41-sfm-point-cloud-reconstruction",children:"4.1 SfM Point Cloud Reconstruction"}),"\n",(0,t.jsxs)(i.p,{children:[(0,t.jsx)(i.strong,{children:"Structure from Motion (SfM)"})," method is employed for 3D reconstruction from multi-view images, obtaining crop canopy point clouds. SfM reconstruction results are primarily used for:"]}),"\n",(0,t.jsx)(i.h4,{id:"application-scenarios",children:"Application Scenarios:"}),"\n",(0,t.jsxs)(i.ul,{children:["\n",(0,t.jsxs)(i.li,{children:[(0,t.jsx)(i.strong,{children:"Canopy height and spatial distribution analysis"}),": Crop height distribution statistics based on point cloud elevation"]}),"\n",(0,t.jsxs)(i.li,{children:[(0,t.jsx)(i.strong,{children:"Population-scale structural phenotyping"}),": Calculation of point cloud density, spatial heterogeneity metrics"]}),"\n",(0,t.jsxs)(i.li,{children:[(0,t.jsx)(i.strong,{children:"Joint analysis with orthophotos and DSM"}),": Multi-source data fusion enhances phenotypic accuracy"]}),"\n"]}),"\n",(0,t.jsx)(i.p,{children:(0,t.jsx)(i.img,{alt:"SfM Point Cloud Reconstruction Diagram",src:e(30564).A+"",width:"868",height:"487"})}),"\n",(0,t.jsx)(i.h3,{id:"42-3d-gaussian-splatting-3dgs",children:"4.2 3D Gaussian Splatting (3DGS)"}),"\n",(0,t.jsxs)(i.p,{children:["Building upon SfM, ",(0,t.jsx)(i.strong,{children:"3D Gaussian Splatting (3DGS)"})," method is introduced for continuous surface representation of crop canopies. 3DGS is primarily used for:"]}),"\n",(0,t.jsx)(i.h4,{id:"technical-advantages",children:"Technical Advantages:"}),"\n",(0,t.jsxs)(i.ul,{children:["\n",(0,t.jsxs)(i.li,{children:[(0,t.jsx)(i.strong,{children:"Fine structure expression"}),": High-resolution continuous geometric representation"]}),"\n",(0,t.jsxs)(i.li,{children:[(0,t.jsx)(i.strong,{children:"Continuous geometric representation of complex canopies"}),": Handling intricate structures like branch-leaf intersections"]}),"\n",(0,t.jsxs)(i.li,{children:[(0,t.jsx)(i.strong,{children:"3D visualization and structure exploration"}),": Supporting interactive 3D browsing and analysis"]}),"\n"]}),"\n",(0,t.jsx)(i.h2,{id:"5-3d-crop-phenotyping-quantification-and-machine-learning-analysis",children:"5. 3D Crop Phenotyping Quantification and Machine Learning Analysis"}),"\n",(0,t.jsx)(i.h3,{id:"51-3d-structural-phenotypic-feature-construction",children:"5.1 3D Structural Phenotypic Feature Construction"}),"\n",(0,t.jsx)(i.p,{children:"3D structural phenotypic features are constructed based on crop point clouds, including:"}),"\n",(0,t.jsx)(i.h4,{id:"phenotypic-features",children:"Phenotypic Features:"}),"\n",(0,t.jsxs)(i.ul,{children:["\n",(0,t.jsxs)(i.li,{children:[(0,t.jsx)(i.strong,{children:"Canopy height distribution characteristics"}),": Height statistics (mean, variance, quantiles)"]}),"\n",(0,t.jsxs)(i.li,{children:[(0,t.jsx)(i.strong,{children:"Point cloud density and spatial heterogeneity metrics"}),": Spatial distribution uniformity, aggregation degree"]}),"\n",(0,t.jsxs)(i.li,{children:[(0,t.jsx)(i.strong,{children:"Canopy surface undulation and roughness parameters"}),": Surface roughness, undulation amplitude"]}),"\n"]}),"\n",(0,t.jsx)(i.h3,{id:"52-machine-learning-modeling",children:"5.2 Machine Learning Modeling"}),"\n",(0,t.jsx)(i.p,{children:"Machine learning methods are further employed to establish mapping relationships between 3D structural phenotypes and crop biological traits, achieving quantitative analysis of crop phenotypes."}),"\n",(0,t.jsx)(i.h4,{id:"analysis-workflow",children:"Analysis Workflow:"}),"\n",(0,t.jsxs)(i.ol,{children:["\n",(0,t.jsxs)(i.li,{children:[(0,t.jsx)(i.strong,{children:"Feature engineering"}),": Extract multi-scale phenotypic features from 3D point clouds"]}),"\n",(0,t.jsxs)(i.li,{children:[(0,t.jsx)(i.strong,{children:"Model training"}),": Use random forest, gradient boosting, and other algorithms to build predictive models"]}),"\n",(0,t.jsxs)(i.li,{children:[(0,t.jsx)(i.strong,{children:"Validation and evaluation"}),": Assess model performance through cross-validation"]}),"\n",(0,t.jsxs)(i.li,{children:[(0,t.jsx)(i.strong,{children:"Application and promotion"}),": Apply models to large-scale crop phenotypic monitoring"]}),"\n"]}),"\n",(0,t.jsx)(i.h2,{id:"6-canopypc-plant-canopy-point-cloud-processing-tool",children:"6. CanopyPC: Plant Canopy Point Cloud Processing Tool"}),"\n",(0,t.jsxs)(i.p,{children:[(0,t.jsx)(i.strong,{children:"CanopyPC"})," is a Python-based tool for processing and analyzing UAV-CCO (Unmanned Aerial Vehicle Cross-Circular Oblique) reconstructed plant canopy point clouds. This tool provides a complete pipeline for segmenting, analyzing, and visualizing 3D point cloud data of plant canopies."]}),"\n",(0,t.jsx)(i.h3,{id:"features",children:"Features"}),"\n",(0,t.jsx)(i.h4,{id:"ground-canopy-segmentation",children:"Ground-Canopy Segmentation"}),"\n",(0,t.jsxs)(i.p,{children:["Separate ground and plant canopy points using ",(0,t.jsx)(i.strong,{children:"Cloth Simulation Filter (CSF)"})]}),"\n",(0,t.jsx)(i.h4,{id:"point-cloud-preprocessing",children:"Point Cloud Preprocessing"}),"\n",(0,t.jsxs)(i.ul,{children:["\n",(0,t.jsxs)(i.li,{children:[(0,t.jsx)(i.strong,{children:"Noise removal"})," using statistical outlier detection"]}),"\n",(0,t.jsxs)(i.li,{children:[(0,t.jsx)(i.strong,{children:"Small cluster removal"})," using DBSCAN"]}),"\n",(0,t.jsx)(i.li,{children:(0,t.jsx)(i.strong,{children:"Landmark sign removal"})}),"\n",(0,t.jsx)(i.li,{children:(0,t.jsx)(i.strong,{children:"Manual point selection and removal"})}),"\n"]}),"\n",(0,t.jsx)(i.h4,{id:"canopy-row-segmentation",children:"Canopy Row Segmentation"}),"\n",(0,t.jsxs)(i.p,{children:["Automatically segment plant canopies into rows using ",(0,t.jsx)(i.strong,{children:"K-means clustering"})]}),"\n",(0,t.jsx)(i.h4,{id:"geometric-analysis",children:"Geometric Analysis"}),"\n",(0,t.jsxs)(i.ul,{children:["\n",(0,t.jsx)(i.li,{children:(0,t.jsx)(i.strong,{children:"Convex hull volume calculation"})}),"\n",(0,t.jsx)(i.li,{children:(0,t.jsx)(i.strong,{children:"Oriented bounding box (OOBB) analysis"})}),"\n",(0,t.jsx)(i.li,{children:(0,t.jsx)(i.strong,{children:"Projected area calculation"})}),"\n",(0,t.jsx)(i.li,{children:(0,t.jsx)(i.strong,{children:"Plant height statistics"})}),"\n"]}),"\n",(0,t.jsx)(i.h4,{id:"visualization",children:"Visualization"}),"\n",(0,t.jsx)(i.p,{children:"Interactive 3D visualization of point clouds, convex hulls, and bounding boxes"}),"\n",(0,t.jsx)(i.h2,{id:"summary",children:"Summary"}),"\n",(0,t.jsx)(i.p,{children:"This workflow constructs a complete UAV-based 3D crop phenotyping system, from image acquisition to machine learning modeling, achieving quantitative and intelligent analysis of crop phenotypes. This method offers the following advantages:"}),"\n",(0,t.jsxs)(i.ul,{children:["\n",(0,t.jsxs)(i.li,{children:[(0,t.jsx)(i.strong,{children:"High precision"}),": 3D reconstruction provides rich spatial structural information"]}),"\n",(0,t.jsxs)(i.li,{children:[(0,t.jsx)(i.strong,{children:"High efficiency"}),": Automated workflow supports large-scale monitoring"]}),"\n",(0,t.jsxs)(i.li,{children:[(0,t.jsx)(i.strong,{children:"Scalability"}),": Machine learning models can be transferred to different crops and environments"]}),"\n"]}),"\n",(0,t.jsx)(i.hr,{}),"\n",(0,t.jsx)(i.p,{children:(0,t.jsx)(i.em,{children:"This article introduces the complete workflow of UAV-based 3D crop phenotyping. For questions or collaboration opportunities, feel free to contact and exchange ideas."})})]})}function h(n={}){const{wrapper:i}={...(0,s.R)(),...n.components};return i?(0,t.jsx)(i,{...n,children:(0,t.jsx)(d,{...n})}):d(n)}},28453:(n,i,e)=>{e.d(i,{R:()=>r,x:()=>a});var o=e(96540);const t={},s=o.createContext(t);function r(n){const i=o.useContext(s);return o.useMemo((function(){return"function"==typeof n?n(i):{...i,...n}}),[i,n])}function a(n){let i;return i=n.disableParentContext?"function"==typeof n.components?n.components(t):n.components||t:r(n.components),o.createElement(s.Provider,{value:i},n.children)}},30564:(n,i,e)=>{e.d(i,{A:()=>o});const o=e.p+"assets/images/f3dr-8d3d33f8d6290b36d2eb7078cf427fc6.png"},46682:n=>{n.exports=JSON.parse('{"permalink":"/zh-Hans/blog/uav-3d-crop-phenotyping","editUrl":"https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/blog/2024-07-07-uav-3d-crop-phenotyping.md","source":"@site/blog/2024-07-07-uav-3d-crop-phenotyping.md","title":"UAV 3D Crop Phenotyping: From Image Acquisition to Machine Learning Modeling","description":"Comprehensive guide to UAV-based 3D crop phenotyping workflow, including CCO flight path design, orthophoto mosaic, SfM and 3DGS 3D reconstruction, and 3D structural phenotyping with machine learning analysis.","date":"2024-07-07T00:00:00.000Z","tags":[{"inline":false,"label":"UAV","permalink":"/zh-Hans/blog/tags/uav","description":"Unmanned Aerial Vehicle"},{"inline":false,"label":"3D Reconstruction","permalink":"/zh-Hans/blog/tags/3d-reconstruction-2","description":"3D model reconstruction technology"},{"inline":false,"label":"Phenomics","permalink":"/zh-Hans/blog/tags/phenomics","description":"Quantitative analysis of plant traits across scales"},{"inline":false,"label":"Machine Learning","permalink":"/zh-Hans/blog/tags/machine-learning-2","description":"Machine learning techniques and applications"},{"inline":false,"label":"Agriculture","permalink":"/zh-Hans/blog/tags/agriculture","description":"Agricultural technology and applications"}],"readingTime":3.93,"hasTruncateMarker":true,"authors":[{"name":"Liangchao Deng","title":"Ph.D. Candidate @ SHZU @CAS-Cemps","url":"https://github.com/smiler488","page":{"permalink":"/zh-Hans/blog/authors/liangchao"},"socials":{"x":"https://x.com/smiler488","github":"https://github.com/smiler488"},"imageURL":"/zh-Hans/img/cv_person.png","key":"liangchao"}],"frontMatter":{"slug":"uav-3d-crop-phenotyping","title":"UAV 3D Crop Phenotyping: From Image Acquisition to Machine Learning Modeling","authors":["liangchao"],"tags":["UAV","3D Reconstruction","Phenomics","Machine Learning","Agriculture"],"description":"Comprehensive guide to UAV-based 3D crop phenotyping workflow, including CCO flight path design, orthophoto mosaic, SfM and 3DGS 3D reconstruction, and 3D structural phenotyping with machine learning analysis."},"unlisted":false,"prevItem":{"title":"Guide to 3D Reconstruction with AI","permalink":"/zh-Hans/blog/hunyuan3d-plant-reconstruction-guide"},"nextItem":{"title":"Root Quantify: Python-Based Root System Image Processing Tool","permalink":"/zh-Hans/blog/root-quantify"}}')},57386:(n,i,e)=>{e.d(i,{A:()=>o});const o=e.p+"assets/images/cco-a3f05a0205f19eef2bf776ea0594921f.png"}}]);